# RAG Project

> **Tutorial de como este projeto foi desenvolvido, passo a passo.**

## Conte√∫do

 - **Implementa√ß√£o**
   - [`Adicionando .editorconfig e .gitignore`](#editorconfig-gitignore)
   - [`Criando vari√°veis de Ambiente (.env.dev, .env.prod e .env.example)`](#env-variables)
   - [`Iniciando o projeto com "poetry init"`](#poetry-init)
   - [`Instalando e configurando o Taskipy`](#taskipy-settings-pyproject)
   - [`Instalando/Configurando/Exportando o Django + Uvicorn`](#django-settings)
   - [`Criando o container com PostgreSQL (db)`](#db-container)
   - [`Criando o container com Redis (redis_cache)`](#redis-container)
   - [`Script de inicializa√ß√£o do servi√ßo web (entrypoint.sh)`](#entrypoint-sh)
   - [`Criando o Dockerfile do servi√ßo web`](#web-dockerfiler)
   - [`Criando o docker compose para o container web`](#web-docker-compose)
   - [`Configurando o Django para reconhecer o PostgreSQL (+ .env) como Banco de Dados`](#django-postgresql-settings)
   - [`Criando o container Nginx (nginx | +Reverse Proxy)`](#nginx-container)
   - [`Instalando e configurando o Ruff`](#ruff-settings-pyproject)
   - [`Instalando e configurando o Pytest`](#pytest-settings-pyproject)
   - [`Instalando e configurando o pre-commit`](#precommit-settings)
   - [`Criando o diret√≥rio (pasta) .github/workflows/`](#github-workflows)
   - [`Criando o workflow lint.yml`](#github-workflows-lint-yml)
 - **Testes:**
   - [`Criando testes para o manage.py`](#manage-py-tests)
   - [`Testando se a URL /admin/ est√° registrada corretamente`](#test-admin-url-is-registered)
   - [`Testando se a aplica√ß√£o ASGI do Django √© criada corretamente`](#test-asgi-application-is-created)
<!---
[WHITESPACE RULES]
- Same topic = "40" Whitespace character.
- Different topic = "200" Whitespace character.
--->









































































































<!--- ( Implementa√ß√£o ) --->

---

<div id="editorconfig-gitignore"></div>

## `Adicionando .editorconfig e .gitignore`

De in√≠cio vamos adicionar os arquivos `.editorconfig` e `.gitignore` na raiz do projeto:

[.editorconfig](../.editorconfig)
```conf
# top-most EditorConfig file
root = true

# Unix-style newlines with a newline ending every file
[*]
end_of_line = lf
insert_final_newline = true
charset = utf-8

# 4 space indentation
[*.{py,html, js}]
indent_style = space
indent_size = 4

# 2 space indentation
[*.{json,y{a,}ml,cwl}]
indent_style = space
indent_size = 2
```

[.gitignore](../.gitignore)
```conf
√â muito grande n√£o vou exibir...
```




















































---

<div id="env-variables"></div>

## `Criando vari√°veis de Ambiente (.env.dev, .env.prod e .env.example)`

> **Nunca reutilize o mesmo `.env` para *dev* e *prod*.**

 - Mesmo em projeto pessoal.
 - Isso evita 90% dos acidentes.

### `üéØ Objetivo`

Ter:

 - Vari√°veis claramente separadas por ambiente
 - Zero risco de misturar dev ‚Üî prod
 - F√°cil uso no Docker Compose, Django e CI

**‚úÖ Estrutura recomendada de arquivos:**
```bash
.env.dev
.env.prod
.env.example
```

 - `.env.dev (desenvolvimento)`
   - Nomes expl√≠citos
   - Senha fraca OK (local)
   - DEBUG=True
   - Ambiente identificado
 - `.env.prod (produ√ß√£o)`
   - Senhas fortes
   - DEBUG=False
   - Nada que sugira dev
 - `.env.example (para versionar)`
   - Pode ser comitado como exemplo

### `Como usar isso no Django?`

[core/settings.py](../core/settings.py)
```python
import os

DJANGO_ENV = os.getenv("DJANGO_ENV", "dev")
DEBUG = os.getenv("DEBUG") == "True"

DATABASES = {
    "default": {
        "ENGINE": "django.db.backends.postgresql",
        "NAME": os.environ["POSTGRES_DB"],
        "USER": os.environ["POSTGRES_USER"],
        "PASSWORD": os.environ["POSTGRES_PASSWORD"],
        "HOST": os.environ["POSTGRES_HOST"],
        "PORT": os.environ["POSTGRES_PORT"],
    }
}
```

 - üìå Simples
 - üìå Expl√≠cito
 - üìå Sem m√°gica

### `üîê Seguran√ßa (nota importante)`

Mesmo em produ√ß√£o:

 - N√£o coloque `.env.prod` no reposit√≥rio
 - Em cloud:
   - Use secrets (GitHub Actions, Docker secrets, etc.)
 - Local prod (VPS):
   - Arquivo `.env.prod` fora do repo

### `üìÑ .env.example`

O [.env.example](../.env.example) √© o contrato do projeto, ent√£o ele precisa ser did√°tico, completo e seguro.

> **üëâ Esse arquivo PODE e DEVE ser versionado.**

[.env.example](../.env.example)
```bash
# ============================================================================
# CONFIGURA√á√ÉO DO POSTGRESQL
# ============================================================================
POSTGRES_DB=                # Nome do banco de dados a ser criado (ex: rag_dev, rag_prod)
POSTGRES_USER=              # Usu√°rio do banco de dados
POSTGRES_PASSWORD=          # Senha do banco de dados
POSTGRES_HOST=db            # Nome do servi√ßo (container) do banco no docker-compose
POSTGRES_PORT=5432          # Porta padr√£o do PostgreSQL


# ============================================================================
# CONFIGURA√á√ÉO DO REDIS
# ============================================================================
REDIS_HOST=redis            # Nome do servi√ßo (container) do Redis no docker-compose
REDIS_PORT=6379             # Porta padr√£o do Redis


# ============================================================================
# CONFIGURA√á√ÉO DO DJANGO
# ============================================================================
DJANGO_SECRET_KEY=          # Chave secreta do Django (NUNCA versionar valores reais)
DJANGO_DEBUG=               # True = Desenvolvimento | False = Produ√ß√£o
DJANGO_ALLOWED_HOSTS=       # Hosts permitidos (ex: *, localhost, dominio.com)

# ID do site para o framework de sites do Django (usado pelo django-allauth)
DJANGO_SITE_ID=1            # Geralmente 1
DJANGO_SITE_DOMAIN=         # Dominio do site (ex: localhost ou seu-dominio.com)
DJANGO_SITE_NAME=           # Nome exibido do site


# ============================================================================
# CONFIGURA√á√ÉO DO UVICORN
# ============================================================================
UVICORN_HOST=0.0.0.0        # 0.0.0.0 = escutar em todas as interfaces (Docker)
UVICORN_PORT=8000           # Porta interna do app Django


# ============================================================================
# CONFIGURA√á√ÉO DO CELERY
# ============================================================================
CELERY_BROKER_URL=          # URL do broker do Celery (ex: redis://redis:6379/0)
CELERY_RESULT_BACKEND=      # URL do backend de resultados (ex: redis://redis:6379/1)

# Executa tasks de forma s√≠ncrona (sem fila) quando True
# √ötil para testes unit√°rios
CELERY_TASK_ALWAYS_EAGER=   # True ou False

# Propaga exce√ß√µes quando tasks s√£o executadas de forma eager
# √ötil para debugging em testes
CELERY_TASK_EAGER_PROPAGATES=  # True ou False


# ============================================================================
# CONFIGURA√á√ïES DO SUPERUSU√ÅRIO INICIAL
# ============================================================================
DJANGO_SUPERUSER_USERNAME=  # Nome de usu√°rio do superusu√°rio inicial
DJANGO_SUPERUSER_EMAIL=     # Email do superusu√°rio inicial
DJANGO_SUPERUSER_PASSWORD=  # Senha do superusu√°rio inicial


# ============================================================================
# CONFIGURA√á√ïES DE AUTENTICA√á√ÉO SOCIAL (OAUTH2)
# ============================================================================
# Client ID do Google OAuth2
GOOGLE_CLIENT_ID=           # Client ID fornecido pelo Google

# Client Secret do Google OAuth2
GOOGLE_CLIENT_SECRET=       # Client Secret fornecido pelo Google

# Client ID do GitHub OAuth2
GITHUB_CLIENT_ID=           # Client ID fornecido pelo GitHub

# Client Secret do GitHub OAuth2
GITHUB_CLIENT_SECRET=       # Client Secret fornecido pelo GitHub
```

### `Vendo as vari√°veis de ambiente dentro do container`

Uma coisa interessante √© verificar se essas vari√°veis de ambiente est√£o sendo reconhecidas dentro do container:

```bash
docker inspect <container-name> --format='{{.Config.Env}}'
```

**OUTPUT:**
```bash
[DJANGO_SITE_ID=1 DJANGO_SUPERUSER_USERNAME=drigols REDIS_HOST=redis POSTGRES_HOST=db DJANGO_SUPERUSER_PASSWORD=drigols GOOGLE_CLIENT_SECRET=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 CELERY_TASK_ALWAYS_EAGER=False GOOGLE_CLIENT_ID=265398246169-0eppnll3l45mhkppo08r02lapoj0a35i.apps.googleusercontent.com CELERY_BROKER_URL=redis://redis:6379/0 GITHUB_CLIENT_SECRET=fabc42b71aef3341ac8693d680b3c756ac82d03d CELERY_TASK_EAGER_PROPAGATES=True UVICORN_PORT=8000 POSTGRES_USER=rag_user_dev REDIS_PORT=6379 UVICORN_HOST=0.0.0.0 GITHUB_CLIENT_ID=Ov23lidBPkHBQ0NCKEM2 DJANGO_SECRET_KEY=django-insecure-dev-key POSTGRES_PORT=5432 CELERY_RESULT_BACKEND=redis://redis:6379/1 DJANGO_SUPERUSER_EMAIL=drigols.creative@gmail.com DJANGO_SITE_DOMAIN=localhost POSTGRES_PASSWORD=rag_pass_dev DJANGO_ALLOWED_HOSTS=* DJANGO_DEBUG=True DJANGO_SITE_NAME=Localhost POSTGRES_DB=rag_dev PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/postgresql/15/bin GOSU_VERSION=1.19 LANG=en_US.utf8 PG_MAJOR=15 PG_VERSION=15.15-1.pgdg13+1 PGDATA=/var/lib/postgresql/data]
```

> **NOTE:**  
> Uma observa√ß√£o aqui √© que vamos continuar utilizando s√≥ um [.env](../.env) porque nosso projeto por agora s√≥ vai utilizar um √∫nico [docker-compose.yml](../docker-compose.yml.




















































---

<div id="poetry-init"></div>

## `Iniciando o projeto com "poetry init"`

Agora vamos iniciar nosso projeto com `poetry init`:

```bash
poetry init
```




















































---

<div id="taskipy-settings-pyproject"></div>

## `Instalando e configurando o Taskipy`

> Aqui, n√≥s vamos *instalar* e *configurar* o **Taskipy** no nosso projeto.

De in√≠cio vamos atualizar a vers√£o do Python no nosso [pyproject.toml](../pyproject.toml) para que o Taskipy funcione corretamente:

[pyproject.toml](../pyproject.toml)
```toml
requires-python = ">=3.12,<4.0"
```

√ìtimo, agora vamos de fato instala o Taskipy na sua √∫ltima vers√£o com o comando:

```bash
poetry add --group dev taskipy@latest
```



















































---

<div id="django-settings"></div>

## `Instalando/Configurando/Exportando o Django + Uvicorn`

 - Antes de criar um container contendo o Django, vamos instalar e configurar o `Django` + `Uvicorn` na nossa m√°quina local (host).
 - **NOTE:** Vai ser como um modelo que n√≥s vamos utilizar dentro do container.

#### `Instala√ß√µes iniciais`

De in√≠cio, vamos instalar as bibliotecas necess√°rias:

```bash
poetry add django@latest
```

```bash
poetry add uvicorn@latest
```

#### `Criando o projeto Django (core)`

Agora vamos criar o projeto (core) que vai ter as configura√ß√µes iniciais do Django:

```bash
django-admin startproject core .
```

#### `Configurando os arquivos: templates, static e media`

> Aqui n√≥s tamb√©m vamos fazer as configura√ß√µes iniciais do Django que ser√£o.

Fazer o Django identificar onde estar√£o os arquivos `templates`, `static` e `media`:

[core/settings.py](../core/settings.py)
```python
TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [BASE_DIR / 'templates'],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]



STATIC_URL = '/static/'
STATICFILES_DIRS = [BASE_DIR / 'static']
STATIC_ROOT = BASE_DIR / 'staticfiles'

MEDIA_URL = '/media/'
MEDIA_ROOT = BASE_DIR / 'media'
```

At√© aqui est√° quase tudo ok para criarmos um Container com `Django` e `Uvicorn`...

> Mas, antes de criar nossos containers, precisamos gerar os `requirements.txt (produ√ß√£o)` e `requirements-dev.txt (desenvolvimento)`.

**Mas, primeiro devemos instalar o plugin "export" do Poetry:**
```bash
poetry self add poetry-plugin-export
```

Agora vamos gerar o `requirements.txt` de *produ√ß√£o*:

**Produ√ß√£o:**
```bash
task exportprod
```

Continuando, agora vamos gerar `requirements-dev.txt` (esse √© mais utilizado durante o desenvolvimento para quem n√£o usa o Poetry):

**Desenvolvimento:**
```bash
poetry export --without-hashes --with dev --format=requirements.txt --output=requirements-dev.txt
```

Agora, vamos gerar o `requirements.txt` de *produ√ß√£o*:

**Produ√ß√£o:**
```bash
poetry export --without-hashes --format=requirements.txt --output=requirements.txt
```

Tamb√©m seria interessante criar comandos Taskipy para esse processo de exportar as depend√™ncias:

[pyproject.toml](../pyproject.toml)
```toml
[tool.taskipy.tasks]
# ------------------ ( Project Management ) -----------------
exportdev = "poetry export --without-hashes --with dev --format=requirements.txt --output=requirements-dev.txt"
exportprod = "poetry export --without-hashes --format=requirements.txt --output=requirements.txt"
```




















































---

<div id="db-container"></div>

## `Criando o container com PostgreSQL (db)`

> Aqui n√≥s vamos entender e criar um container contendo o `Banco de Dados PostgreSQL`.

 - **Fun√ß√£o:**
   - Armazenar dados persistentes da aplica√ß√£o (usu√°rios, arquivos, prompts, etc.).
 - **Quando usar:**
   - Sempre que precisar de um banco de dados relacional robusto.
 - **Vantagens:**
   - ACID (consist√™ncia e confiabilidade).
   - Suporte avan√ßado a consultas complexas.
 - **Desvantagens:**
   - Mais pesado que bancos NoSQL para dados muito simples.

Antes de criar nosso container contendo o PostgreSQL vamos criar as vari√°veis de ambiente para esse container:

[.env](../.env)
```bash
# ============================================================================
# CONFIGURA√á√ÉO DO POSTGRESQL
# ============================================================================
POSTGRES_DB=rag_db         # Nome do banco de dados a ser criado
POSTGRES_USER=raguser      # Usu√°rio do banco de dados
POSTGRES_PASSWORD=ragpass  # Senha do banco de dados
POSTGRES_HOST=db           # Nome do servi√ßo (container) do banco no docker-compose
POSTGRES_PORT=5432         # Porta padr√£o do PostgreSQL
```

 - `POSTGRES_DB` ‚Üí nome do banco criado automaticamente ao subir o container.
 - `POSTGRES_USER` ‚Üí usu√°rio administrador do banco.
 - `POSTGRES_PASSWORD` ‚Üí senha do usu√°rio do banco.
 - `POSTGRES_HOST` ‚Üí para o Django se conectar, usamos o nome do servi√ßo (db), n√£o localhost, pois ambos est√£o na mesma rede docker.
 - `POSTGRES_PORT` ‚Üí porta padr√£o 5432.

Continuando, o arquivo [docker-compose.yml](../docker-compose.yml) para o nosso container *PostgreSQL* ficar√° assim:

[docker-compose.yml](../docker-compose.yml)
```yml
services:
  # PostgreSQL Service
  db:
    image: postgres:15
    container_name: postgresql
    restart: always
    env_file: .env
    ports:
      - 5432:5432
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend

volumes:
  postgres_data:

networks:
  backend:
```

 - `db`
   - Nome do *servi√ßo (container)* criado pelo docker-compose.
 - `image: postgres:15`
   - Pega a vers√£o 15 oficial do PostgreSQL no Docker Hub.
 - `container_name: postgresql`
   - Nome fixo do container (para facilitar comandos como docker logs postgresql).
 - `restart: always`
   - üîπ O container vai voltar sempre que o Docker daemon subir, independente do motivo da parada.
   - üîπ Mesmo se voc√™ der *docker stop*, quando o host reiniciar o container volta sozinho.
   - üëâ Bom para produ√ß√£o quando voc√™ quer *99% de disponibilidade*.
 - `env_file: .env`
   - Carrega vari√°veis de ambiente do arquivo `.env`.
 - `volumes:`
     - `postgres_data:` ‚Üí Volume docker (Named Volume).
     - `/var/lib/postgresql/data` ‚Üí pasta interna do container onde o Postgres armazena os dados.
 - `ports: 5432:5432`
   - `Primeiro 5432:` ‚Üí porta no host (sua m√°quina).
   - `Segundo 5432:` ‚Üí porta dentro do container onde o Postgres est√° rodando.
   - **NOTE:** Isso permite que voc√™ use o psql ou qualquer ferramenta de banco de dados (DBeaver, TablePlus, etc.) diretamente do seu PC.
 - `volumes:`
   - `postgres_data:` ‚Üí Volume docker (Named Volume).
 - `networks: backend`
   - Coloca o container na rede backend para comunica√ß√£o interna segura.

Aqui, tamb√©m seria interessante ter comando Taskipy para gerenciar nossos containers:

[pyproject.toml](../pyproject.toml)
```toml
[tool.taskipy.tasks]
# -------------- ( General Docker Management ) --------------
start_compose = 'docker compose up -d'
down_compose = 'docker compose down'
restart_compose = 'docker restart $(docker ps -q)'
build_compose = 'docker compose up --build -d'
clean_compose = """
docker stop $(docker ps -aq) 2>/dev/null || true &&
docker rm $(docker ps -aq) 2>/dev/null || true &&
docker rmi -f $(docker images -aq) 2>/dev/null || true &&
docker volume rm $(docker volume ls -q) 2>/dev/null || true &&
docker system prune -a --volumes -f
"""
```

√ìtimo, agora vamos subir o container:

```bash
task start_compose
```

√ìtimo, agora se voc√™ desejar se conectar nesse Banco de Dados via *bash* utilize o seguinte comando (As vezes √© necess√°rio esperar o container/banco de dados subir):

**Entrar no container "postgresql" via bash:**
```bash
docker exec -it postgresql bash
```

**Entra no banco de sados a partir das vari√°veis de ambiente:**
```bash
psql -U "$POSTGRES_USER" -d "$POSTGRES_DB"
```

**Ver em qual Banco de Dados e usu√°rio est√° conectado:**
```bash
\c
```

**OUTPUT:**
```bash
You are now connected to database "rag_db" as user "raguser".
```

> **E os volumes como eu vejo?**

```bash
docker volume ls
```

**OUTPUT:**
```bash
DRIVER    VOLUME NAME
local     rag-project_postgres_data
```

N√≥s tamb√©m podemos inspecionar esse volume:

```bash
docker volume inspect rag-project_postgres_data
```

**OUTPUT:**
```bash
[
    {
        "CreatedAt": "2026-01-11T13:35:59-03:00",
        "Driver": "local",
        "Labels": {
            "com.docker.compose.config-hash": "5dc3d628a7c7fc208c1a083f74bde3e0acba02c0a3a313cd96bc1e1ecaa7ba3a",
            "com.docker.compose.project": "rag-project",
            "com.docker.compose.version": "2.39.1",
            "com.docker.compose.volume": "postgres_data"
        },
        "Mountpoint": "/var/lib/docker/volumes/rag-project_postgres_data/_data",
        "Name": "rag-project_postgres_data",
        "Options": null,
        "Scope": "local"
    }
]
```

 - `Mountpoint`
   - O *Mountpoint* √© onde os arquivos realmente ficam, mas n√£o √© recomendado mexer manualmente l√°.
   - Para interagir com os dados, use o *container* ou ferramentas do pr√≥prio servi√ßo (por exemplo, psql no Postgres).



















































---

<div id="redis-container"></div>

## `Criando o container com Redis (redis_cache)`

> Aqui n√≥s vamos entender e criar um container contendo o `Redis`.

 - **Fun√ß√£o:**
   - Armazenar dados tempor√°rios (cache, sess√µes, filas de tarefas).
 - **Quando usar:**
   - Quando for necess√°rio aumentar velocidade de acesso a dados tempor√°rios ou usar filas.
 - **Vantagens:**
   - Muito r√°pido (em mem√≥ria).
   - Perfeito para cache e tarefas ass√≠ncronas.
 - **Desvantagens:**
   - N√£o indicado para dados cr√≠ticos (pode perder dados em caso de rein√≠cio)

Antes de criar nosso container contendo o *Redis* vamos criar as vari√°veis de ambiente para esse container:

[.env](../.env)
```bash
# ============================================================================
# CONFIGURA√á√ÉO DO REDIS
# ============================================================================
REDIS_HOST=redis  # Nome do servi√ßo (container) do Redis no docker-compose
REDIS_PORT=6379   # Porta padr√£o do Redis
```

 - `REDIS_HOST` ‚Üí nome do servi√ßo no docker-compose.
 - `REDIS_PORT` ‚Üí porta padr√£o 6379.
 - **NOTE:** O Redis ser√° usado como cache em possivelmente fila de tarefas (com Celery, RQ ou outro).

Continuando, o arquivo [docker-compose.yml](../docker-compose.yml) para o nosso container *Redis* ficar√° assim:

[docker-compose.yml](../docker-compose.yml)
```yml
services:
  # Redis Service
  redis:
    image: redis:7
    container_name: redis_cache
    restart: always
    env_file: .env
    volumes:
      - redis_data:/data
    networks:
      - backend

volumes:
  redis_data:

networks:
  backend:
```

 - `redis:`
   - Nome do *servi√ßo (container)* criado pelo docker-compose.
 - `image: redis:7`
   - Pega a vers√£o 7 oficial do Redis no Docker Hub.
 - `container_name: redis_cache`
   - Nome fixo do container (para facilitar comandos como docker logs redis_cache).
 - `restart: always`
   - üîπ O container vai voltar sempre que o Docker daemon subir, independente do motivo da parada.
   - üîπ Mesmo se voc√™ der *docker stop*, quando o host reiniciar o container volta sozinho.
   - üëâ Bom para produ√ß√£o quando voc√™ quer *99% de disponibilidade*.
 - `env_file: .env`
   - Carrega vari√°veis de ambiente do arquivo `.env`.
 - `volumes:`
     - `redis_data:` ‚Üí Volume docker (Named Volume).
     - `/data` ‚Üí pasta interna do container onde o Redis armazena os dados.
 - `networks: backend`
   - S√≥ est√° acess√≠vel dentro da rede interna backend (n√£o exp√µe porta para fora).

Agora √© s√≥ subir o container, igual fizemos com o PostgreSQL:

```bash
task start_compose
```

> **E os volumes como eu vejo?**

```bash
docker volume ls
```

**OUTPUT:**
```bash
DRIVER    VOLUME NAME
local     ragproject_redis_data
```

N√≥s tamb√©m podemos inspecionar esse volume:

```bash
docker volume inspect ragproject_redis_data
```

**OUTPUT:**
```bash
[
    {
        "CreatedAt": "2025-11-10T07:35:18-03:00",
        "Driver": "local",
        "Labels": {
            "com.docker.compose.config-hash": "75e82217f9045c1c51074e1c927a0ba2be71af9e784263a59e10d6bfb25e12e6",
            "com.docker.compose.project": "ragproject",
            "com.docker.compose.version": "2.39.1",
            "com.docker.compose.volume": "redis_data"
        },
        "Mountpoint": "/var/lib/docker/volumes/ragproject_redis_data/_data",
        "Name": "ragproject_redis_data",
        "Options": null,
        "Scope": "local"
    }
]
```

 - `Mountpoint`
   - O *Mountpoint* √© onde os arquivos realmente ficam, mas n√£o √© recomendado mexer manualmente l√°.
   - Para interagir com os dados, use o *container* ou ferramentas do pr√≥prio servi√ßo (por exemplo, psql no Postgres).



















































---

<div id="entrypoint-sh"></div>

## `Script de inicializa√ß√£o do servi√ßo web (entrypoint.sh)`

> O arquivo [entrypoint.sh](../entrypoint.sh) √© o script de inicializa√ß√£o que *n√≥s vamos utilizar dentro do container*.

Ele √© executado *antes do Django subir (no container)*, garantindo que o ambiente esteja corretamente preparado para rodar a aplica√ß√£o com seguran√ßa.

As responsabilidades principais desse script s√£o:

 - Criar diret√≥rios essenciais (static, media e staticfiles);
 - Ajustar permiss√µes e ownership desses diret√≥rios;
 - Garantir que a aplica√ß√£o n√£o rode como root, mas sim como um usu√°rio n√£o privilegiado (appuser);
 - Executar o comando final do container de forma segura.

Vamos come√ßar adicionado `#!/bin/bash` no in√≠cio do arquivo para dizer que ele √© um script Bash:

[entrypoint.sh](../entrypoint.sh)
```bash
#!/bin/bash
```

Agora vamos adicionar `set -e` para garantir que o script encerre imediatamente se algum comando falhar:

[entrypoint.sh](../entrypoint.sh)
```bash
set -e
```

No container vai ser necess√°rio n√≥s criamos os diret√≥rios `/code/static`, `/code/media`, `/code/staticfiles`:

[entrypoint.sh](../entrypoint.sh)
```bash
# Cria diret√≥rios necess√°rios se n√£o existirem
mkdir -p /code/static /code/media /code/staticfiles
```

 - `-p`
   - O par√¢metro `-p` no comando `mkdir` tem duas fun√ß√µes principais:
   - **1. Criar diret√≥rios pais (parents):**
     - Se voc√™ especificar um caminho com v√°rios n√≠veis de diret√≥rios que n√£o existem, o `-p` cria todos os diret√≥rios intermedi√°rios necess√°rios.
     - Exemplo: `mkdir -p /code/static`
       - Se `/code` n√£o existir, o `-p` cria primeiro `/code` e depois `/code/static`.
       - Sem o `-p`, voc√™ receberia um erro dizendo que `/code` n√£o existe.
   - **2. N√£o dar erro se o diret√≥rio j√° existir:**
     - Se o diret√≥rio j√° existe, o `mkdir` normalmente retorna um erro.
     - Com `-p`, o comando simplesmente ignora e n√£o retorna erro.
     - Sem `-p`:
       - `mkdir /tmp/teste`
       - `mkdir /tmp/teste`  # Erro: diret√≥rio j√° existe
     - Com `-p`:
       - `mkdir -p /tmp/teste`
       - `mkdir -p /tmp/teste`  # Sem erro
 - **NOTE:** Ou seja, o `-p` √© importante para garantir que o script n√£o gere errando, fazendo o `set -e` parar o script.

Agora, n√≥s vamos fazer esses diret√≥rios que foram criados dentro do container terem as seguintes permiss√µe:

[entrypoint.sh](../entrypoint.sh)
```bash
# Ajusta permiss√µes e ownership dos diret√≥rios
# Garante que o usu√°rio appuser (UID 1000) possa escrever neles
chmod -R 755 /code/static /code/media /code/staticfiles
```

 - `-R  (Recursive)`
   - Aplica as permiss√µes *recursivamente*, ou seja, no diret√≥rio e em *todos* os arquivos e subdiret√≥rios dentro dele.
 - `755 (Permiss√µes)`
   - Define as permiss√µes em formato *octal*:
     - `7 (propriet√°rio):` leitura + escrita + execu√ß√£o (4+2+1)
     - `5 (grupo):` leitura + execu√ß√£o (4+0+1)
     - `5 (outros):` leitura + execu√ß√£o (4+0+1)
   - Em termos pr√°ticos:
     - `rwxr-xr-x = 755`

### `Entendendo o "appuser"`

Dentro do contexto de Docker, o `appuser` √© um **usu√°rio n√£o-root** que deve ser criado no [Dockerfile](../Dockerfile) para executar a aplica√ß√£o com mais seguran√ßa.

> **Por que isso existe?**  

 - Por padr√£o, processos dentro de containers Docker rodam como **root (UID 0)**, o que √© um risco de seguran√ßa. 
 - Uma boa pr√°tica √© criar um usu√°rio espec√≠fico para rodar a aplica√ß√£o.

Na pr√°tica, no [Dockerfile](../Dockerfile), vamos criar o `appuser` com o UID 1000 e o GID 1000:

[Dockerfile](../Dockerfile)
```dockerfile
# Cria o usu√°rio appuser
RUN useradd -m -u 1000 appuser

# Mudar para esse usu√°rio
USER appuser
```

Sabendo, que esse usu√°rio ser√° criado automaticamente quando o container for criado, n√≥s vamos obter o `UID` e `GID` dele, com o script de inicialita√ß√£o [entrypoint.sh](../entrypoint.sh):

[entrypoint.sh](../entrypoint.sh)
```bash
# Descobre o UID/GID do "appuser" que FOI CRIADO no Dockerfile
APPUSER_UID=$(id -u appuser 2>/dev/null || echo "1000")
APPUSER_GID=$(id -g appuser 2>/dev/null || echo "1000")
```

Continuando, no nosso script vamos criar um `if` que vai verificar se usu√°rio **root (UID 0)** quem rodou o script:

[entrypoint.sh](../entrypoint.sh)
```bash
if [ "$(id -u)" = "0" ]; then
```

 - `id -u`
   - Retorna o UID (User ID) do usu√°rio atual.
   - 0 ‚Üí usu√°rio root
   - 1000 ‚Üí usu√°rio comum
   - 999 ‚Üí outro usu√°rio n√£o-root

Agora, se o usu√°rio que rodou o script dentro do container for **root (UID 0)** vamos definir `appuser` como dono das pastas `/code/static`, `/code/media` e `/code/staticfiles`. Isso evita que `set -e` mate o container por erro de permiss√£o.

[entrypoint.sh](../entrypoint.sh)
```bash
if [ "$(id -u)" = "0" ]; then
    chown -R ${APPUSER_UID}:${APPUSER_GID} \
        /code/static /code/media /code/staticfiles 2>/dev/null || true
```

Agora dentro do if n√≥s vamos adicionar o seguinte comando:

[entrypoint.sh](../entrypoint.sh)
```bash
if [ "$(id -u)" = "0" ]; then
    ...
    exec gosu appuser "$@"
```

Este comando faz **duas coisas principais**: troca de usu√°rio e executa um comando.

 - 1. **`exec`** - Substitui√ß√£o de processo
   - O `exec` √© um comando **built-in do shell** que:
     - **Substitui** o processo atual (o script entrypoint.sh) pelo novo comando
     - **N√£o cria um processo filho**, ele literalmente substitui o processo
     - O script **termina aqui** e √© substitu√≠do pelo novo comando
     - O novo comando herda o **PID do processo original** (geralmente PID 1 no Docker)
   - **Por que isso √© importante no Docker?**
     - O processo com PID 1 √© especial, ele recebe sinais do sistema (SIGTERM, SIGINT)
     - Com `exec`, sua aplica√ß√£o recebe esses sinais diretamente
     - Sem `exec`, o script ficaria rodando e a aplica√ß√£o seria um processo filho, podendo n√£o receber os sinais corretamente
 - 2. `gosu` - Troca de usu√°rio
   - O gosu √© uma ferramenta leve para trocar de usu√°rio, similar ao `sudo` ou `su`, mas:
     - Otimizada para containers Docker
     - N√£o cria processos desnecess√°rios (mais limpo que `su -c`)
     - Mais simples e seguro que usar sudo dentro de containers
     - **NOTE:** Precisa ser instalado no Dockerfile: `RUN apt-get install -y gosu`

√ìtimo, se o usu√°rio que rodar o script dentro do container for **root (UID 0)**, ele vai ser trocado para o `appuser` e o comando vai ser executado.

> Mas e se o usu√°rio que rodou o script dentro do container for **n√£o root (UID 1000)**?

Nesse, caso n√≥s vamos criar o `else` com o seguinte comando:

[entrypoint.sh](../entrypoint.sh)
```bash
if [ "$(id -u)" = "0" ]; then
  ...
else
    # Se j√° estiver rodando como "appuser", apenas executa
    exec "$@"
fi
```

Como o container **j√° est√° rodando como appuser** (n√£o √© root), o script:

 - N√ÉO precisa trocar de usu√°rio (pula o gosu)
 - N√ÉO precisa ajustar permiss√µes com chown (j√° foram ajustadas antes ou n√£o s√£o necess√°rias)
 - Apenas executa o comando passado ao container

### `Script completo`

No fim, n√≥s vamos ter o seguinte script:

[entrypoint.sh](../entrypoint.sh)
```bash
#!/bin/bash

set -e

# Cria diret√≥rios necess√°rios se n√£o existirem
mkdir -p /code/static /code/media /code/staticfiles

# Ajusta permiss√µes e ownership dos diret√≥rios
# Garante que o usu√°rio appuser (UID 1000) possa escrever neles
chmod -R 755 /code/static /code/media /code/staticfiles

# Descobre o UID/GID do "appuser" que FOI CRIADO no Dockerfile
APPUSER_UID=$(id -u appuser 2>/dev/null || echo "1000")
APPUSER_GID=$(id -g appuser 2>/dev/null || echo "1000")

if [ "$(id -u)" = "0" ]; then
    chown -R ${APPUSER_UID}:${APPUSER_GID} \
        /code/static /code/media /code/staticfiles 2>/dev/null || true
    exec gosu appuser "$@"
else
    # Se j√° estiver rodando como "appuser", apenas executa
    exec "$@"
fi
```



















































---

<div id="web-dockerfiler"></div>

## `Criando o Dockerfile do servi√ßo web`

Antes de criar o container contendo o *Django* e o *Uvicorn*, vamos criar o nosso Dockerfile...

> **Mas por que eu preciso de um Dockerfile para o Django + Uvicorn?**

**NOTE:**  
O Dockerfile √© onde voc√™ diz **como** essa imagem ser√° constru√≠da.

> **O que o Dockerfile faz nesse caso?**

 - Escolhe a imagem base (ex.: python:3.12-slim) para rodar o Python.
 - Instala as depend√™ncias do sistema (por exemplo, libpq-dev para PostgreSQL).
 - Instala as depend√™ncias Python (pip install -r requirements.txt).
 - Copia o c√≥digo do projeto para dentro do container.
 - Define o diret√≥rio de trabalho (WORKDIR).
 - Configura o comando de entrada.
 - Organiza assets est√°ticos e outras configura√ß√µes.

> **Quais as vantagens de usar o Dockerfile?**

 - **Reprodutibilidade:**
   - Qualquer pessoa consegue subir seu projeto com o mesmo ambiente que voc√™ usa.
 - **Isolamento:**
   - Evita conflitos de vers√£o no Python e depend√™ncias.
 - **Customiza√ß√£o:**
   - Voc√™ pode instalar pacotes de sistema ou bibliotecas espec√≠ficas.
 - **Portabilidade:**
   - Mesma imagem funciona no seu PC, no servidor ou no CI/CD.

O nosso [Dockerfile](../Dockerfile) vai ficar da seguinte maneira:

[Dockerfile](../Dockerfile)
```bash
# ===============================
# 1Ô∏è‚É£ Imagem base
# ===============================
FROM python:3.12-slim

# ===============================
# 2Ô∏è‚É£ Configura√ß√£o de ambiente
# ===============================
WORKDIR /code
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PYTHONPATH=/code

# ===============================
# 3Ô∏è‚É£ Depend√™ncias do sistema
# ===============================
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    netcat-traditional \
    bash \
    gosu \
    && rm -rf /var/lib/apt/lists/*

# ===============================
# 4Ô∏è‚É£ Instalar depend√™ncias Python
# ===============================
COPY requirements-dev.txt /code/
RUN pip install --upgrade pip && pip install -r requirements-dev.txt

# ===============================
# 5Ô∏è‚É£ Copiar c√≥digo do projeto
# ===============================
COPY . /code/

# ===============================
# 6Ô∏è‚É£ Ajustes de produ√ß√£o
# ===============================
# Criar usu√°rio n√£o-root para seguran√ßa
RUN adduser --disabled-password --no-create-home appuser && \
    chown -R appuser /code

# Copia e configura o entrypoint
COPY entrypoint.sh /entrypoint.sh
RUN chmod +x /entrypoint.sh

# Define o entrypoint (roda como root para ajustar permiss√µes)
# O entrypoint vai mudar para appuser antes de executar o comando
ENTRYPOINT ["/entrypoint.sh"]

# Mant√©m como root no Dockerfile - o entrypoint gerencia a mudan√ßa de usu√°rio
# Isso permite que o entrypoint ajuste permiss√µes antes de mudar para appuser

# ===============================
# 7Ô∏è‚É£ Porta exposta (Uvicorn usa 8000 por padr√£o)
# ===============================
EXPOSE 8000

# ===============================
# 8Ô∏è‚É£ Comando padr√£o
# ===============================
# Mant√©m o container rodando e abre um shell se usado com
# `docker run` sem sobrescrever comando.
CMD ["bash"]
```

> **NOTE:**  
> Acredito que o [Dockerfile](../Dockerfile) est√° bem descritivo, por isso n√£o vou comentar os comandos.



















































---

<div id="web-docker-compose"></div>

#### `Criando o docker compose para o container web`

> Aqui vamos entender e criar um container contendo o `Django` e o `Uvicorn`.

 - **Fun√ß√£o:**
   - Executar a aplica√ß√£o Django em produ√ß√£o.
 - **Quando usar:**
   - Sempre para servir sua aplica√ß√£o backend.
 - **Vantagens:**
   - Uvicorn √© um servidor WSGI otimizado para produ√ß√£o.
   - Separa l√≥gica da aplica√ß√£o da entrega de arquivos est√°ticos.
 - **Desvantagens:**
   - N√£o serve arquivos est√°ticos eficientemente.

Antes de criar nosso container contendo o *Django* e o *Uvicorn*, vamos criar as vari√°veis de ambiente para esse container:

[.env](../.env)
```bash
# ============================================================================
# CONFIGURA√á√ÉO DO DJANGO
# ============================================================================
DJANGO_SECRET_KEY=djangopass                      # Chave secreta do Django para criptografia e seguran√ßa
DJANGO_DEBUG=True                                 # Tru=Dev / False=Prod
DJANGO_ALLOWED_HOSTS=*                            # '*' = libera para qualquer host (apenas desenvolvimento)
DJANGO_SUPERUSER_USERNAME=drigols                 # Nome de usu√°rio do superusu√°rio
DJANGO_SUPERUSER_EMAIL=drigols.creative@gmail.com # Email do superusu√°rio
DJANGO_SUPERUSER_PASSWORD=drigols                 # Senha do superusu√°rio
# ID do site para o framework de sites do Django (usado pelo allauth)
DJANGO_SITE_ID=1
DJANGO_SITE_DOMAIN=localhost
DJANGO_SITE_NAME=Localhost



# ============================================================================
# CONFIGURA√á√ÉO DO UVICORN
# ============================================================================
UVICORN_HOST=0.0.0.0  # 0.0.0.0 = escutar em todas as interfaces (Docker)
UVICORN_PORT=8000     # Porta interna do app Django
```

Continuando, o arquivo [docker-compose.yml](../docker-compose.yml) para o nosso container *web* ficar√° assim:

[docker-compose.yml](../docker-compose.yml)
```yml
services:
  # Django/Uvicorn Service
    web:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: django
    restart: always
    env_file: .env
    environment:
      DJANGO_SETTINGS_MODULE: core.settings
    command: >
      sh -c "
      until nc -z ${POSTGRES_HOST} ${POSTGRES_PORT}; do
        echo '‚è≥ Waiting for Postgres...';
        sleep 2;
      done &&
      python manage.py migrate &&
      python manage.py collectstatic --noinput &&
      python manage.py runserver ${DJANGO_HOST:-0.0.0.0}:${DJANGO_PORT:-8000}
      "
    volumes:
      - .:/code
      - ./static:/code/staticfiles
      - ./media:/code/media
    depends_on:
      - db
      - redis
    ports:
      - "${UVICORN_PORT}:${UVICORN_PORT}"
    networks:
      - backend

networks:
  backend:
```

> **Uma d√∫vida... tudo que eu modifico no meu projeto principal √© alterado no container?**

**SIM!**  
No nosso caso, sim ‚Äî porque no servi√ßo `web` voc√™ fez este mapeamento:

[docker-compose.yml](../docker-compose.yml)
```yaml
volumes:
  - .:/code
```

Isso significa que:

 - O diret√≥rio atual no seu `host (.)` √© montado dentro do container em `/code`.
 - Qualquer altera√ß√£o nos arquivos do seu projeto no host aparece instantaneamente no container.
 - E o inverso tamb√©m vale: se voc√™ mudar algo dentro do container nessa pasta, muda no seu host.

Por fim, vamos subir o container web:

```bash
task start_compose
```

Se tudo ocorrer bem voc√™ pode abrir no navegador:

 - [http://localhost:8000/](http://localhost:8000/)

Aqui, voc√™ tamb√©m pode ver os logs do container:

```bash
task logs django
```

**OUTPUT:**
```bash
docker logs django
Operations to perform:
  Apply all migrations: admin, auth, contenttypes, sessions
Running migrations:
  Applying contenttypes.0001_initial... OK
  Applying auth.0001_initial... OK
  Applying admin.0001_initial... OK
  Applying admin.0002_logentry_remove_auto_add... OK
  Applying admin.0003_logentry_add_action_flag_choices... OK
  Applying contenttypes.0002_remove_content_type_name... OK
  Applying auth.0002_alter_permission_name_max_length... OK
  Applying auth.0003_alter_user_email_max_length... OK
  Applying auth.0004_alter_user_username_opts... OK
  Applying auth.0005_alter_user_last_login_null... OK
  Applying auth.0006_require_contenttypes_0002... OK
  Applying auth.0007_alter_validators_add_error_messages... OK
  Applying auth.0008_alter_user_username_max_length... OK
  Applying auth.0009_alter_user_last_name_max_length... OK
  Applying auth.0010_alter_group_name_max_length... OK
  Applying auth.0011_update_proxy_permissions... OK
  Applying auth.0012_alter_user_first_name_max_length... OK
  Applying sessions.0001_initial... OK

130 static files copied to '/code/staticfiles'.
Watching for file changes with StatReloader
Performing system checks...

System check identified no issues (0 silenced).
January 12, 2026 - 00:06:52
Django version 6.0.1, using settings 'core.settings'
Starting development server at http://0.0.0.0:8000/
Quit the server with CONTROL-C.

WARNING: This is a development server. Do not use it in a production setting. Use a production WSGI or ASGI server instead.
For more information on production servers see: https://docs.djangoproject.com/en/6.0/howto/deployment/
[12/Jan/2026 00:07:13] "GET / HTTP/1.1" 200 12068
Not Found: /favicon.ico
[12/Jan/2026 00:07:13] "GET /favicon.ico HTTP/1.1" 404 2206
```



























































---

<div id="django-postgresql-settings"></div>

## `Configurando o Django para reconhecer o PostgreSQL (+ .env) como Banco de Dados`

Antes de come√ßar a configurar o Django para reconhecer o PostgreSQL como Banco de Dados, vamos fazer ele reconhecer as vari√°veis de ambiente dentro de [core/settings.py](../core/settings.py).

Primeiro, vamos instalar o `python-dotenv` e `psycopg2-binary`:

```bash
poetry add python-dotenv@latest
```

```bash
poetry add psycopg2-binary@latest
```

**NOTE:**  
Aqui tamb√©m vai ser importante lembrar de exportar essas bibliotecas nos nossos [requirements.txt](../requirements.txt) e [requirements-dev.txt](../requirements-dev.txt):

```bash
task exportdev
```

```bash
task exportprod
```

√ìtimo, agora vamos iniciar uma inst√¢ncia de `python-dotenv`:

[core/settings.py](../core/settings.py)
```python
import os

from pathlib import Path
from dotenv import load_dotenv

load_dotenv()
```

> **E agora, como testar que est√° funcionando?**

Primeiro, imagine que n√≥s temos as seguinte vari√°veis de ambiente:

[.env](../.env)
```bash
# ============================================================================
# CONFIGURA√á√ÉO DO POSTGRESQL
# ============================================================================
POSTGRES_DB=rag_db         # Nome do banco de dados a ser criado
POSTGRES_USER=raguser      # Usu√°rio do banco de dados
POSTGRES_PASSWORD=ragpass  # Senha do banco de dados
POSTGRES_HOST=db           # Nome do servi√ßo (container) do banco no docker-compose
POSTGRES_PORT=5432         # Porta padr√£o do PostgreSQL
```

Agora vamos abrir um **shell interativo do Django**, ou seja, um terminal Python (REPL) com o Django j√° carregado, permitindo testar c√≥digo com acesso total ao projeto.

√â parecido com abrir um python normal, mas com estas diferen√ßas:

| Recurso                           | Python normal | `manage.py shell` |
| --------------------------------- | ------------- | ----------------- |
| Carrega o Django automaticamente  | ‚ùå N√£o       | ‚úÖ Sim            |
| Consegue acessar `settings.py`    | ‚ùå           | ‚úÖ                |
| Consegue acessar models           | ‚ùå           | ‚úÖ                |
| Consegue consultar banco de dados | ‚ùå           | ‚úÖ                |
| L√™ o `.env` (se Django carregar)  | ‚ùå           | ‚úÖ                |
| √ötil para debugar                 | Razo√°vel      | Excelente         |

```bash
python manage.py shell

6 objects imported automatically (use -v 2 for details).
Python 3.12.3 (main, Aug 14 2025, 17:47:21) [GCC 13.3.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
(InteractiveConsole)

>>> import os

>>> print(os.getenv("POSTGRES_HOST"))
db

>>> print(os.getenv("POSTGRES_PASSWORD"))
ragpass
```

> **NOTE:**  
> Vejam que realmente n√≥s estamos conseguindo acessar as vari√°veis de ambiente.

Continuando, agora vamos dizer ao Django qual Banco de Dados vamos utilizar.

Por exemplo:

[core/settings.py](../core/settings.py)
```python
DATABASES = {
    "default": {
        "ENGINE": "django.db.backends.postgresql",
        "NAME": os.getenv("POSTGRES_DB"),
        "USER": os.getenv("POSTGRES_USER"),
        "PASSWORD": os.getenv("POSTGRES_PASSWORD"),
        "HOST": os.getenv("POSTGRES_HOST", "localhost"),
        "PORT": os.getenv("POSTGRES_PORT", 5432),
    }
}
```

No exemplo acima n√≥s temos um dicion√°rio que informa ao Django como conectar ao banco de dados:

 - `ENGINE`
   - Qual backend/driver o Django usa ‚Äî aqui, PostgreSQL.
 - `NAME`
   - Nome do banco.
 - `USER`
   - Usu√°rio do banco.
 - `PASSWORD`
   - Senha do usu√°rio.
 - `HOST`
   - Host/hostname do servidor de banco.
 - `PORT`
   - Porta TCP onde o Postgres escuta.

#### `O que os.getenv('VAR', 'default') faz, exatamente?`

`os.getenv` vem do m√≥dulo padr√£o `os` e faz o seguinte:

 - Tenta ler a vari√°vel de ambiente chamada 'VAR' (por exemplo POSTGRES_DB);
 - Se existir, retorna o valor da vari√°vel de ambiente;
 - Se n√£o existir, retorna o valor padr√£o passado como segundo argumento ('default').

#### `Por que √†s vezes PASSAMOS um valor padr√£o (default) no c√≥digo?`

 - *Conforto no desenvolvimento local:* evita quebrar o projeto se voc√™ esquecer de definir `.env`.
 - *Documenta√ß√£o inline:* d√° uma ideia do nome esperado (easy_rag, 5432, etc.).
 - *Teste r√°pido:* voc√™ pode rodar `manage.py` localmente sem carregar vari√°veis.

> **NOTE:**  
> Mas aten√ß√£o: os valores padr√µes n√£o devem conter segredos reais (ex.: supersecret) no reposit√≥rio p√∫blico ‚Äî isso √© um risco de seguran√ßa.

#### `Por que voc√™ n√£o deveria colocar senhas no c√≥digo?`

 - Reposit√≥rios (Git) podem vazar ou ser lidos por terceiros.
 - C√≥digo pode acabar em backups, imagens Docker, etc.
 - Dif√≠cil rotacionar/chavear senhas se espalhadas pelo reposit√≥rio.

> **Regra pr√°tica:**  
> - *"NUNCA"* colocar credenciais reais em `settings.py`.
> - Use `.env` (n√£o comitado) ou um *"secret manager"*.



















































---

<div id="nginx-container"></div>

## `Criando o container Nginx (nginx | +Reverse Proxy)`

Para entender a necessidade do Nginx, vamos come√ßar imaginando que n√≥s criamos uma conta de **super usu√°rio** no Django (pode ser na sua m√°quina local mesmo):

**Roda/Executa o comando "createsuperuser" a partir do servi√ßor "web":**
```bash
docker compose exec web python manage.py createsuperuser
```

Agora √© s√≥ abrir o **Django Admin** e verificar se temos a tabela `users`:

 - [http://127.0.0.1:8000/admin/](http://127.0.0.1:8000/admin/)

![img](images/nginx-01.png)  

Vejam que:

 - Est√° tudo mal formado;
 - Sem estiliza√ß√£o (CSS)...

> **Por que isso?**

 - **Executando/Rodando na m√°quina local**:
   - Quando voc√™ roda o Django na sua m√°quina local (fora do container), ele serve os arquivos est√°ticos automaticamente porque:
     - `DEBUG=True`
     - O servidor de desenvolvimento (runserver) serve /static/ diretamente.
 - **Executando/Rodando no container**:
   - Mas dentro do Docker, o **servidor Uvicorn n√£o serve arquivos est√°ticos por padr√£o**.
   - Uvicorn √© um ASGI server puro, *n√£o um servidor web completo (como o runserver do Django)*.
   - **NOTE:** Por isso, o Django Admin aparece sem CSS.

> **Como resolver isso? Usando Nginx**

Para ambientes de produ√ß√£o profissional, voc√™ deve:

 - Deixar o Uvicorn apenas para as requisi√ß√µes din√¢micas (ASGI);
 - Deixar o Nginx servir `/static/` e `/media/` diretamente.

Ou seja, o Nginx vai ter as seguintes caracter√≠sticas (nesse projeto):

 - **Fun√ß√£o:**
   - Servir arquivos est√°ticos e atuar como *proxy reverso* para o Django.
 - **Quando usar:**
   - Sempre em produ√ß√£o para seguran√ßa e desempenho.
 - **Reverse proxy:**
   - Receber as requisi√ß√µes HTTP/HTTPS dos clientes.
   - Redirecionar (proxy_pass) para seu container Django (web).
   - Isso permite que seu backend fique ‚Äúescondido‚Äù atr√°s do Nginx, ganhando seguran√ßa e performance.
 - **Servir arquivos est√°ticos e de m√≠dia diretamente:**
   - Em Django, arquivos est√°ticos (/static/) e de upload (/media/) n√£o devem ser servidos pelo Uvicorn (ineficiente).
   - O Nginx √© muito melhor para isso, ent√£o ele entrega esses arquivos direto do volume.
 - **HTTPS (SSL/TLS):**
   - Configurar certificados (ex.: Let‚Äôs Encrypt) para rodar sua aplica√ß√£o com HTTPS.
   - O Django n√£o lida com certificados nativamente, ent√£o o Nginx faz esse papel.
 - **Balanceamento e cache (futuro):**
   - Se voc√™ crescer, pode colocar v√°rios containers de Django e usar o Nginx como load balancer.
   - Tamb√©m pode configurar cache de p√°ginas ou de assets.
 - **Vantagens:**
   - Muito r√°pido para servir arquivos est√°ticos.
   - HTTPS e balanceamento de carga.
 - **Desvantagens:**
   - Exige configura√ß√£o inicial extra.
 - **üëâ Resumindo:**
   - O Nginx √© a porta de entrada da sua aplica√ß√£o, cuidando de performance, seguran√ßa e organiza√ß√£o.

**NOTE:**  
Mas antes de criar e iniciar o nosso container com Nginx, vamos alterar uma configura√ß√£o no nosso container `web`:

[docker-compose.yml](../docker-compose.yml)
```yaml
  web:

    ...

    expose:
      - "8000"

    ...
```

> **O que mudou?**

 - **Antes n√≥s tinhamos:**
   - `ports: "${UVICORN_PORT}:${UVICORN_PORT}"`
   - ‚úÖ Antes (ports) ‚Äî Tornava a porta 8000 acess√≠vel externamente no host (ex.: http://localhost:8000).
 - **Agora n√≥s temos:**
   - `expose: ["8000"]`
   - ‚úÖ Agora (expose) ‚Äî Deixa a porta 8000 vis√≠vel apenas entre containers na rede Docker, invis√≠vel fora.

Com essa altera√ß√£o feita, agora vamos criar/configurar o [docker-compose.yml](../docker-compose.yml) para o nosso container `nginx`:

[docker-compose.yml](../docker-compose.yml)
```yml
services:
  nginx:
    image: nginx:1.27
    container_name: nginx
    restart: always
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/conf.d/default.conf
      - ./static:/code/staticfiles
      - ./media:/code/media
    depends_on:
      - web
    networks:
      - backend

networks:
  backend:
```

 - `nginx:`
   - Nome do *servi√ßo (container)* criado pelo docker-compose.
 - `image: nginx:1.27`
   - Pega a vers√£o 1.27 oficial do Nginx no Docker Hub.
 - `container_name: nginx_reverse_proxy`
   - Nome fixo do container (para facilitar comandos como docker logs nginx_server).
 - `restart: always`
   - üîπ O container vai voltar sempre que o Docker daemon subir, independente do motivo da parada.
   - üîπ Mesmo se voc√™ der *docker stop*, quando o host reiniciar o container volta sozinho.
   - üëâ Bom para produ√ß√£o quando voc√™ quer *99% de disponibilidade*.
 - `ports:`
   - Mapeia portas do host para o container:
     - `80:80` ‚Üí HTTP
     - `443:443` ‚Üí HTTPS
 - `volumes:`
   - Pasta local `./nginx/conf` ‚Üí onde ficam configs do Nginx.
   - Volumes `static` e `media` para servir arquivos.
 - `depends_on:`
   - S√≥ inicia depois que o `Django (web)` estiver rodando.
 - `networks: backend`
   - Rede interna para conversar com Django sem expor a aplica√ß√£o diretamente.

Agora, n√≥s precisamos criar o arquivo de configura√ß√£o do `Nginx`:

[nginx.conf](../nginx/nginx.conf)
```bash
# ============================================================================
# CONFIGURA√á√ÉO DO SERVIDOR WEB NGINX
# ============================================================================
#
# Este arquivo configura o Nginx como proxy reverso para a aplica√ß√£o
# Django, servindo arquivos est√°ticos e m√≠dia diretamente e repassando
# requisi√ß√µes din√¢micas para o servidor de aplica√ß√£o (Uvicorn/Gunicorn).
#
# Estrutura:
# - Configura√ß√µes gerais do servidor
# - Servir arquivos est√°ticos (CSS, JS, imagens)
# - Servir arquivos de m√≠dia (uploads dos usu√°rios)
# - Proxy reverso para aplica√ß√£o Django
#
# ============================================================================
# CONFIGURA√á√ÉO DO SERVIDOR VIRTUAL
# ============================================================================

server {
    # Porta na qual o servidor escuta requisi√ß√µes HTTP
    listen 80;
    
    # Nome do servidor (aceita qualquer nome de dom√≠nio)
    # Em produ√ß√£o, substitua por um dom√≠nio espec√≠fico
    server_name _;

    # ========================================================================
    # CONFIGURA√á√ïES GLOBAIS DO SERVIDOR
    # ========================================================================
    
    # Tamanho m√°ximo do corpo da requisi√ß√£o (0 = ilimitado)
    # Permite uploads de qualquer tamanho - a valida√ß√£o √© feita pelo Django
    # Em produ√ß√£o, considere definir um limite adequado (ex: 100M)
    client_max_body_size 0;

    # ========================================================================
    # SERVI√áO DE ARQUIVOS EST√ÅTICOS
    # ========================================================================
    
    # Localiza√ß√£o para servir arquivos est√°ticos (CSS, JS, imagens)
    # Estes arquivos s√£o coletados pelo Django via 'collectstatic'
    location /static/ {
        # Caminho no sistema de arquivos onde os est√°ticos est√£o
        alias /code/staticfiles/;
        
        # Cache do navegador por 30 dias
        expires 30d;
        
        # Desabilita logs de acesso para melhorar performance
        access_log off;
        
        # Habilita listagem de diret√≥rios (√∫til para debug)
        autoindex on;
    }

    # ========================================================================
    # SERVI√áO DE ARQUIVOS DE M√çDIA
    # ========================================================================
    
    # Localiza√ß√£o para servir arquivos de m√≠dia (uploads dos usu√°rios)
    # Estes arquivos s√£o enviados pelos usu√°rios e armazenados pelo Django
    location /media/ {
        # Caminho no sistema de arquivos onde os arquivos de m√≠dia est√£o
        alias /code/media/;
        
        # Cache do navegador por 30 dias
        expires 30d;
        
        # Desabilita logs de acesso para melhorar performance
        access_log off;
        
        # Habilita listagem de diret√≥rios (√∫til para debug)
        autoindex on;
    }

    # ========================================================================
    # PROXY REVERSO PARA APLICA√á√ÉO DJANGO
    # ========================================================================
    
    # Todas as outras requisi√ß√µes s√£o repassadas para o servidor Django
    # O Nginx atua como proxy reverso, melhorando performance e seguran√ßa
    location / {
        # URL do servidor de aplica√ß√£o (Django via Uvicorn/Gunicorn)
        # 'web' √© o nome do servi√ßo no Docker Compose
        proxy_pass http://web:8000;
        
        # Headers necess√°rios para o Django funcionar corretamente
        # Preserva o host original da requisi√ß√£o
        proxy_set_header Host $host;
        
        # IP real do cliente (importante para logs e seguran√ßa)
        proxy_set_header X-Real-IP $remote_addr;
        
        # Cadeia de IPs em caso de m√∫ltiplos proxies
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        
        # Protocolo original (http ou https)
        # Necess√°rio para o Django detectar requisi√ß√µes HTTPS
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

Por fim, vamos subir o container `nginx`:

```bash
task start_compose
```

 - **üß© Fluxo de funcionamento**
   - `Uvicorn (web)` executa o Django e responde √†s rotas din√¢micas.
   - `Nginx` recebe todas as requisi√ß√µes HTTP externas:
     - `/static/` ‚Üí servido diretamente da pasta staticfiles;
     - `/media/` ‚Üí servido diretamente da pasta media;
     - outras rotas ‚Üí redirecionadas para o container web (Uvicorn).
   - `PostgreSQL` e Redis s√£o usados internamente via rede backend.

Agora tente abrir:

 - [http://localhost:8000/](http://localhost:8000/)
 - [http://localhost:8000/admin/](http://localhost:8000/admin/)

> **What? N√£o funcionou!**  
> üëâ Porque o Nginx est√° na porta 80 e o Uvicorn est√° atr√°s dele, **exposto (expose)** apenas internamente no Docker.

Agora para acessar nossa aplica√ß√£o `web` primeiro n√≥s devemos passar pelo container `nginx`:

 - [http://localhost/](http://localhost/)
 - [http://localhost/admin/](http://localhost/admin/)

> **Explicando brevemente:**  
> O container *nginx* atua como `reverse proxy`; ele recebe todas as requisi√ß√µes HTTP (nas portas 80/443) e as encaminha internamente para o container web (Uvicorn/Django).

Agora voc√™ pode abrir o seu Django Admin que estar√° tudo dispon√≠vel pelo Nginx:

![img](images/nginx-02.png)  

> **Mas como eu testo se meu nginx est√° funcionando corretamente?**

Primeiro, vamos ver se h√° mensagem de erro dentor do container `nginx`:

```bash
docker logs nginx
```

**OUTPUT:**
```bash
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: /etc/nginx/conf.d/default.conf differs from the packaged version
/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2025/11/10 13:10:11 [notice] 1#1: using the "epoll" event method
2025/11/10 13:10:11 [notice] 1#1: nginx/1.27.5
2025/11/10 13:10:11 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14)
2025/11/10 13:10:11 [notice] 1#1: OS: Linux 6.6.87.2-microsoft-standard-WSL2
2025/11/10 13:10:11 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576
2025/11/10 13:10:11 [notice] 1#1: start worker processes
2025/11/10 13:10:11 [notice] 1#1: start worker process 28
2025/11/10 13:10:11 [notice] 1#1: start worker process 29
2025/11/10 13:10:11 [notice] 1#1: start worker process 30
2025/11/10 13:10:11 [notice] 1#1: start worker process 31
2025/11/10 13:10:11 [notice] 1#1: start worker process 32
2025/11/10 13:10:11 [notice] 1#1: start worker process 33
2025/11/10 13:10:11 [notice] 1#1: start worker process 34
2025/11/10 13:10:11 [notice] 1#1: start worker process 35
172.18.0.1 - - [10/Nov/2025:13:10:28 +0000] "GET / HTTP/1.1" 200 12068 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:10:28 +0000] "GET /favicon.ico HTTP/1.1" 404 2201 "http://localhost/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:10:39 +0000] "GET /admin/ HTTP/1.1" 302 0 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:10:39 +0000] "GET /admin/login/?next=/admin/ HTTP/1.1" 200 4173 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:15:32 +0000] "GET / HTTP/1.1" 200 12068 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:18:29 +0000] "GET / HTTP/1.1" 200 12068 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:18:29 +0000] "GET /favicon.ico HTTP/1.1" 404 2201 "http://localhost/" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:18:30 +0000] "GET /admin/ HTTP/1.1" 302 0 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
172.18.0.1 - - [10/Nov/2025:13:18:30 +0000] "GET /admin/login/?next=/admin/ HTTP/1.1" 200 4173 "-" "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/142.0.0.0 Safari/537.36" "-"
```

√ìtimo, agora vamos fazer alguns testes no navegador:

 - http://localhost/static/ ‚Üí deve(ria) exibir arquivos est√°ticos.
 - http://localhost/media/ ‚Üí deve(ria) exibir uploads.

**OUTPUT:**
```bash
403 Forbidden
nginx/1.27.5
```

> **What? N√£o funcionou!**

Agora vamos tentar acessar um arquivo espec√≠fico:

 - http://localhost/static/admin/css/base.css
 - http://localhost/static/admin/img/inline-delete.svg

> **What? Agora funcionou!**

 - Esse comportamento indica que o *Nginx* est√° conseguindo servir arquivos existentes, mas n√£o consegue listar diret√≥rios.
 - **NOTE:** Por padr√£o, o Nginx n√£o habilita autoindex (listagem de diret√≥rios).

Ent√£o:

 - http://localhost/static/admin/css/base.css ‚Üí Funciona porque voc√™ est√° acessando um arquivo espec√≠fico.
 - http://localhost/static/ ‚Üí D√° *403 Forbidden* porque voc√™ est√° acessando o diret√≥rio, e o Nginx n√£o lista o conte√∫do (diret√≥rio) por padr√£o.

> **Como resolver isso?**

#### Habilitar autoindex (n√£o recomendado para produ√ß√£o, s√≥ para teste):

[nginx.conf](../nginx/conf/nginx.conf)
```bash
location /static/ {
    alias /code/staticfiles/;
    autoindex on;
}

location /media/ {
    alias /code/media/;
    autoindex on;
}
```

**For√ßa recriar o container `nginx`**:
```
docker compose up -d --force-recreate nginx
```

> **NOTE:**  
> Isso permite ver os arquivos listados no navegador, mas n√£o √© seguro em produ√ß√£o, porque exp√µe todos os arquivos publicamente.

Agora, abra diretamente algum arquivo, como:

 - [http://localhost/static/admin/css/base.css](http://localhost/static/admin/css/base.css)
 - [http://localhost/media/example.txt](http://localhost/media/example.txt)
   - Crie esse arquivo em `/media (host)` antes de tentar acessar (testar).

Se esses arquivos carregarem, significa que tudo est√° correto para servir conte√∫do est√°tico e uploads, mesmo que a listagem do diret√≥rio n√£o funcione.

> **üí° Resumo:**  
> O erro `403` ao acessar `/static/` ou `/media/` √© normal no Nginx quando voc√™ n√£o habilita `autoindex`. Para produ√ß√£o, voc√™ normalmente n√£o quer listar diret√≥rios, apenas servir arquivos diretamente.

Outra maneira de testar se o Nginx est√° funcionando corretamente seria usar o `curl`:

```bash
curl http://localhost/static/admin/css/base.css -I
```

**OUTPUT:**
```bash
HTTP/1.1 200 OK
Server: nginx/1.27.5
Date: Tue, 19 Aug 2025 02:29:18 GMT
Content-Type: text/css
Content-Length: 22120
Last-Modified: Tue, 19 Aug 2025 01:58:34 GMT
Connection: keep-alive
ETag: "68a3da4a-5668"
Accept-Ranges: bytes
```

```bash
curl http://localhost/media/example.txt -I
```

**OUTPUT:**
```bash
HTTP/1.1 200 OK
Server: nginx/1.27.5
Date: Tue, 19 Aug 2025 02:30:17 GMT
Content-Type: text/plain
Content-Length: 15
Last-Modified: Tue, 19 Aug 2025 02:26:29 GMT
Connection: keep-alive
ETag: "68a3e0d5-f"
Accept-Ranges: bytes
```

```bash
curl http://localhost/static/admin/img/inline-delete.svg -I
```

**OUTPUT:**
```bash
HTTP/1.1 200 OK
Server: nginx/1.27.5
Date: Tue, 19 Aug 2025 02:33:07 GMT
Content-Type: image/svg+xml
Content-Length: 537
Last-Modified: Tue, 19 Aug 2025 01:58:34 GMT
Connection: keep-alive
ETag: "68a3da4a-219"
Accept-Ranges: bytes
```

 - Vejam que quem est√° servindo os dados √© o servidor Nginx e n√£o o Django (container web).
 - Al√©m, disso n√≥s tamb√©m estamos vendo algumas informa√ß√µes interessantes sobre os arquivos:
   - tipo: `text/css`, `text/plain`, `image/svg+xml`, etc.



















































---

<div id="ruff-settings-pyproject"></div>

## `Instalando e configurando o Ruff`

 - Antes de cair de cobe√ßa na codifica√ß√£o do nosso projeto √© interessante criar um mecanismo de verifica√ß√£o de qualidade de c√≥digo.
 - Para isso vamos utilizar a ferramenta [Ruff](https://github.com/astral-sh/ruff)

De in√≠cio, vamos instalar e configurar o **Ruff** no nosso `pyproject.toml`:

```bash
poetry add --group dev ruff@latest
```

Agora, vamos atualizar essa bibliota nos nossos [requirments.txt](../requirements.txt) e [requirments-dev.txt](../requirements-dev.txt):

```bash
task exportdev
```

```bash
task exportprod
```

#### `[tool.ruff]`

> Esse bloco define √†s *Regras Gerais de funcionamento do (Ruff)*.

[pyproject.toml](../pyproject.toml)
```toml
[tool.ruff]
line-length = 79
exclude = [
    "core/settings.py",
]
```

 - `line-length = 79`
   - Define que nenhuma linha de c√≥digo deve ultrapassar 79 caracteres *(seguindo o padr√£o tradicional do PEP 8)*.
   - √â especialmente √∫til para manter legibilidade em terminais com largura limitada.
   - Ruff ir√° avisar (e, se poss√≠vel, corrigir) quando encontrar linhas mais longas.
 - `exclude = ["core/settings.py"]`
   - Define quais arquivos o Ruff deve ignorar:
     - Nesse caso, ele vai ignorar o arquivo `core/settings.py`.

#### `[tool.ruff.lint]`

Esse √© o sub-bloco principal de configura√ß√£o de linting do Ruff, ou seja, onde voc√™ define como o Ruff deve analisar o c√≥digo quanto a erros, estilo, boas pr√°ticas etc.

[pyproject.toml](../pyproject.toml)
```toml
[tool.ruff.lint]
preview = true
select = ['I', 'F', 'E', 'W', 'PL', 'PT']
```

 - `preview = true`
   - Ativa regras experimentais (em fase de teste, mas est√°veis o suficiente).
   - Pode incluir novas verifica√ß√µes que ainda n√£o fazem parte do conjunto padr√£o.
   - √ötil se voc√™ quer estar sempre com o Ruff mais ‚Äúrigoroso‚Äù e atualizado.
 - `select = ['I', 'F', 'E', 'W', 'PL', 'PT']`
   - Define quais conjuntos de regras (lints) o Ruff deve aplicar ao seu c√≥digo. Cada uma dessas letras corresponde a um grupo de regras:
     - `I` ([Isort](https://pycqa.github.io/isort/)): Ordena√ß√£o de imports em ordem alfab√©tica.
     - `F` ([Pyflakes](https://github.com/PyCQA/pyflakes)): Procura por alguns erros em rela√ß√£o a boas pr√°ticas de c√≥digo.
     - `E` ([pycodestyle](https://pycodestyle.pycqa.org/en/latest/)): Erros de estilo de c√≥digo.
     - `W` ([pycodestyle](https://pycodestyle.pycqa.org/en/latest/)): Avisos sobre estilo de c√≥digo.
     - `PL` ([Pylint](https://pylint.pycqa.org/en/latest/index.html)): "erros" em rela√ß√£o a boas pr√°ticas de c√≥digo.
     - `PT` ([flake8-pytest](https://pypi.org/project/flake8-pytest-style/)): Boas pr√°ticas do Pytest.

#### `[tool.ruff.format]`

O bloco [tool.ruff.format] √© usado para configurar o formatador interno do Ruff, que foi introduzido recentemente como uma alternativa ao Black ‚Äî mas com a vantagem de ser muito mais r√°pido.

```toml
[tool.ruff.format]
preview = true
quote-style = "double"
```

 - `preview = true`
   - Ativa regras experimentais (em fase de teste, mas est√°veis o suficiente).
 - `quote-style = "double"`
   - Define o estilo de aspas (duplas no nosso caso) usadas pelo formatador.

Por fim, vamos adicionar o comando Taskipy respons√°vel por executar o Ruff:

[pyproject.toml](../pyproject.toml)
```toml
[tool.taskipy.tasks]
# ------------------------ ( Linting ) ----------------------
pre_lint = 'ruff check --fix'
lint = 'ruff check'
```



















































---

<div id="pytest-settings-pyproject"></div>

## `Instalando e configurando o Pytest`

 - N√≥s tamb√©m vamos precisar de um mecanismo para verifica√ß√£o de qualidade de c√≥digo referente a testes.
 - Para isso vamos utilizar a biblioteca [Pytest](https://github.com/pytest-dev/pytest).

De in√≠cio, vamos *instalar* e *configurar* o **Pytest** no nosso `pyproject.toml`.

```bash
poetry add --group dev pytest@latest
```

```bash
poetry add --group dev pytest-cov@latest
```

```bash
poetry add --group dev pytest-django@latest
```

Agora, vamos atualizar essa bibliota nos nossos [requirments.txt](../requirements.txt) e [requirments-dev.txt](../requirements-dev.txt):

```bash
task exportdev
```

```bash
task exportprod
```

Agora, vamos criar uma se√ß√£o no nosso [pyproject.toml](../pyproject.toml) que √© equivalente a ter um arquivo `pytest.ini` separado:

[pyproject.toml](../pyproject.toml)
```toml
[tool.pytest.ini_options]
DJANGO_SETTINGS_MODULE = "core.settings"
python_files = ["tests.py", "test_*.py", "*_tests.py"]
```

 - `DJANGO_SETTINGS_MODULE = "core.settings"`
   - Define qual arquivo de configura√ß√£o do Django o pytest deve usar durante os testes
   - √â o equivalente a fazer `export DJANGO_SETTINGS_MODULE=core.settings` no terminal
   - **Por que √© necess√°rio?**
     - O Django precisa saber qual settings.py usar para configurar o banco de dados, apps instalados, middlewares, etc.
     - Sem isso, voc√™ receberia erros tipo: "Django is not configured"
 - `python_files = ["tests.py", "test_*.py", "*_tests.py"]`
   - Define quais arquivos o pytest deve considerar como arquivos de teste
   - Aceita 3 padr√µes de nomenclatura:
     - `tests.py` - arquivo √∫nico chamado exatamente "tests.py"
     - `test_*.py` - qualquer arquivo come√ßando com "test_" (ex: test_models.py, test_views.py)
     - `*_tests.py` - qualquer arquivo terminando com "_tests" (ex: models_tests.py, views_tests.py)

**EXEMPLO NA PR√ÅTICA:**
```bash
myapp/
‚îú‚îÄ‚îÄ tests.py          ‚úÖ Ser√° executado
‚îú‚îÄ‚îÄ test_models.py    ‚úÖ Ser√° executado
‚îú‚îÄ‚îÄ test_views.py     ‚úÖ Ser√° executado
‚îú‚îÄ‚îÄ models_tests.py   ‚úÖ Ser√° executado
‚îú‚îÄ‚îÄ views.py          ‚ùå N√ÉO ser√° executado (n√£o segue os padr√µes)
‚îî‚îÄ‚îÄ my_test.py        ‚ùå N√ÉO ser√° executado (n√£o segue os padr√µes)
```

Continuando, agora vamos ativar a descoberta autom√°tica de projetos Django pelo [pytest-django](https://github.com/pytest-dev/pytest-django):

[pyproject.toml](../pyproject.toml)
```toml
[tool.pytest.ini_options]
django_find_project = true
```

 - `django_find_project = true`
   - Diz ao [pytest-django](https://github.com/pytest-dev/pytest-django) para procurar automaticamente a raiz do projeto Django
   - Ele sobe na hierarquia de diret√≥rios at√© encontrar o [manage.py](../manage.py)

**Sem django_find_project = true:**
```bash
# Voc√™ precisa estar EXATAMENTE na raiz do projeto
cd /projeto/
pytest  # ‚úÖ Funciona

cd /projeto/myapp/
pytest  # ‚ùå Erro: Django is not configured
```

**Com django_find_project = true:**
```bash
# Funciona de QUALQUER subdiret√≥rio
cd /projeto/myapp/tests/
pytest  # ‚úÖ Funciona! Encontra o manage.py automaticamente

cd /projeto/myapp/
pytest  # ‚úÖ Funciona!

cd /projeto/
pytest  # ‚úÖ Funciona!
```

Agora, vamos adicionar algumas configura√ß√µes na se√ß√£o que mede a cobertura de testes: `[tool.coverage.run]`

[pyproject.toml](../pyproject.toml)
```toml
[tool.coverage.run]
omit = [
    "*/__init__.py",
    "*/migrations/*",
]
```

> **NOTE:**  
> Na verdade, o que estamos dizendo √© que n√£o vamos medir a cobertura de arquivos `__init__.py` ou `migrations/`

Por fim, vamos adicionar o comando Taskipy respons√°vel por executar o Pytest:

[pyproject.toml](../pyproject.toml)
```toml
[tool.taskipy.tasks]
# ------------------------ ( Testing ) ----------------------
test = "docker compose exec -T web pytest -s -x --cov=. -vv"
post_test = 'docker compose exec -T web coverage html'
```



















































---

<div id="precommit-settings"></div>

## `Instalando e configurando o pre-commit`

Para garantir que antes de cada commit seu projeto passe por:

 - ‚úÖ lint (usando Ruff)
 - ‚úÖ test (com pytest)
 - ‚úÖ coverage

Voc√™ deve usar o pre-commit ‚Äî uma ferramenta leve e ideal para isso. Vamos configurar passo a passo:

```bash
poetry add --group dev pre-commit
```

Novamente, vamos atualizar essa bibliota nos nossos [requirments.txt](../requirements.txt) e [requirments-dev.txt](../requirements-dev.txt):

```bash
task exportdev
```

```bash
task exportprod
```

Agora, vamos inciar o arquivo [.pre-commit-config.yaml](../.pre-commit-config.yaml) com a seguinte configura√ß√£o:

[.pre-commit-config.yaml](../.pre-commit-config.yaml)
```yaml
repos:
  - repo: local
    hooks:
```

### `repos:`

 - A lista de reposit√≥rios de onde os hooks do pre-commit vir√£o
 - Um arquivo .pre-commit-config.yaml pode ter v√°rios reposit√≥rios configurados

**EXEMPLO:**
```yaml
repos:
  - repo: https://github.com/psf/black
    # hooks do black aqui
  
  - repo: https://github.com/pycqa/flake8
    # hooks do flake8 aqui
  
  - repo: local
    # hooks locais aqui
```

### `repo: local`

 - Define um reposit√≥rio do tipo "local"
 - Os hooks N√ÉO v√™m de um reposit√≥rio externo do GitHub
 - Os hooks s√£o definidos no pr√≥prio projeto

**Reposit√≥rio Externo (padr√£o):**
```yaml
- repo: https://github.com/psf/black
  rev: 23.12.1  # Vers√£o espec√≠fica
  hooks:
    - id: black
```

 - ‚úÖ Hooks prontos da comunidade
 - ‚úÖ Versionados e testados
 - ‚ùå Menos flexibilidade

**Reposit√≥rio Local (local):**
```yaml
- repo: local
  hooks:
    - id: meu-hook-customizado
      name: Meu Hook
      entry: ./meu-script.sh
      language: system
```

 - ‚úÖ Total controle e customiza√ß√£o
 - ‚úÖ Usa ferramentas j√° instaladas no projeto
 - ‚úÖ Pode rodar comandos espec√≠ficos do seu workflow
 - ‚ùå Voc√™ mant√©m o c√≥digo

### `hooks:`

 - Lista de hooks (ganchos) que ser√£o executados
 - Cada hook √© uma verifica√ß√£o ou a√ß√£o que roda antes do commit

**Estrutura de um hook:**
```yaml
hooks:
  - id: nome-unico-do-hook
    name: Nome leg√≠vel para humanos
    entry: comando a ser executado
    language: system
    types: [python]
    pass_filenames: false
```

### `Hook do Ruff no Pre-commit`

[.pre-commit-config.yaml](../.pre-commit-config.yaml)
```yaml
repos:
  - repo: local
    hooks:

      # ---------------------------------------------
      #  LINT (somente quando arquivos Python mudarem)
      # ---------------------------------------------
      - id: ruff-lint
        name: ruff check
        entry: task lint
        language: system
        types: [python]
        pass_filenames: false
        exclude: >
          ^(
            .*/migrations/.*|
          )
```

> **O que este hook faz?**

Toda vez que voc√™ tentar fazer um `git commit`, ANTES do commit ser criado, este hook:

 - Roda o comando `task lint` (que executa o Ruff)
 - Verifica se h√° problemas de estilo/qualidade no c√≥digo Python
 - Bloqueia o commit se encontrar erros
 - Permite o commit se tudo estiver OK

 - `id: ruff-lint`
   - Identificador √∫nico do hook dentro do arquivo de configura√ß√£o
   - Usado para referenciar este hook especificamente
   - Voc√™ pode rodar s√≥ este hook com: `pre-commit run ruff-lint`
   - **NOTE:** Deve ser √∫nico dentro do arquivo
 - `name: ruff check`
   - Nome leg√≠vel que aparece no terminal quando o hook executa
   - √â o que voc√™ v√™ na sa√≠da: `ruff check........Passed`
   - Pode ser qualquer texto descritivo
   - N√£o precisa ser igual ao id
 - `entry: task lint`
   - Comando que ser√° executado quando o hook rodar
   - No seu caso, chama `task lint` (definido no [pyproject.toml](../pyproject.toml))
   - task lint provavelmente executa ruff check ou similar
 - `language: system`
   - **Qual "ambiente" usar para executar o comando:**
     - system = usar o ambiente do sistema operacional atual
     - N√£o cria ambiente virtual isolado
     - Usa o Python/ferramentas j√° instaladas na sua m√°quina
   - **Outras op√ß√µes:**
     - python = cria venv isolado e instala depend√™ncias
     - node = usa Node.js
     - docker = roda em container
     - script = executa script shell
   - **Por que system no nosso caso:**
     - N√≥s j√° temos task e ruff instalados
     - Mais r√°pido (n√£o cria ambientes isolados)
     - Usa a vers√£o do Ruff do nosso projeto
 - `types: [python]`
   - Filtro de tipos de arquivos que ativam este hook
   - S√≥ executa se arquivos Python forem modificados
   - Ignora commits que s√≥ alteram `.md`, `.txt`, `.json`, `etc`.
   - **Poderia ser mais de um tipo? SIM!**
     - `types: [python, yaml, toml]`
     - **NOTE:** Nesse caso, o hook ser√° acionado se qualquer arquivo *Python*, *YAML* ou *TOML* for modificado.
 - `pass_filenames: false`
   - Com `pass_filenames: false`, voc√© N√ÉO passar os nomes dos arquivos modificados para o comando.
   - **Com pass_filenames: true (padr√£o):**
     - `# Pre-commit passaria os arquivos modificados:`
     - `task lint myapp/views.py myapp/models.py`
   - **Com pass_filenames: false:**
     - `# Pre-commit roda sem argumentos:`
     - `task lint`
     - `# E o Ruff verifica TODO o projeto, n√£o s√≥ arquivos modificados`
   - **Por que usar false?**
     - ‚úÖ Garante consist√™ncia em TODO o c√≥digo
     - ‚úÖ Ruff √© r√°pido o suficiente para verificar tudo
     - ‚úÖ Evita que erros antigos passem despercebidos
     - ‚ùå Pode ser mais lento em projetos grandes
 - `exclude:`
   - Arquivos ou pastas que devem ser ignorados pelo hook

> **NOTE:**  
> N√£o vou mais explicar os demais hooks linh a linha porque a partir deste j√° d√° para entender a maioria dos comandos.

### `.pre-commit-config.yaml completo`

[.pre-commit-config.yaml](../.pre-commit-config.yaml)
```yaml
repos:
  - repo: local
    hooks:

      # ---------------------------------------------
      #  LINT (somente quando arquivos Python mudarem)
      # ---------------------------------------------
      - id: ruff-lint
        name: ruff check
        entry: task lint
        language: system
        types: [python]
        pass_filenames: false
        exclude: >
          ^(
            .*/migrations/.*|
          )

      # --------------------------------------------------------
      #  PYTEST (executado dentro do container web)
      #  ‚Ä¢ S√≥ roda se arquivos Python mudarem
      #  ‚Ä¢ Usa -T para evitar erro "not a TTY"
      # --------------------------------------------------------
      - id: pytest-test
        name: run pytest inside docker
        entry: docker compose run -T --rm web pytest -s -x --cov=. -vv
        language: system
        types: [python]
        pass_filenames: false
        exclude: >
          ^(
            .*/migrations/.*|
          )

      # --------------------------------------------------------
      #  COVERAGE MINIMUM (falha se < 70%)
      # --------------------------------------------------------
      - id: pytest-coverage
        name: coverage threshold
        entry: docker compose run -T --rm web pytest --cov=. --cov-fail-under=70
        language: system
        types: [python]
        pass_filenames: false
        exclude: >
          ^(
            .*/migrations/.*|
          )
```

Agora n√≥s precisamos instalar o pre-commit para esses hooks funcionarem corretamente:

```bash
pre-commit install
```

#### Dica extra: Se quiser rodar manualmente

```bash
pre-commit run --all-files
```

Por fim, vamos adicionar o comando Taskipy respons√°vel por executar o pre-commit:

[pyproject.toml](../pyproject.toml)
```toml
[tool.taskipy.tasks]
# ---------------------- ( Pre-Commit ) ---------------------
precommit = 'pre-commit run --all-files'
```





















































---

<div id="github-workflows"></div>

## `Criando o diret√≥rio (pasta) .github/workflows/`

Aqui vamos criar o diret√≥rio (pasta) [.github/workflows](.github/workflows) que √© uma pasta especial que fica dentro do seu reposit√≥rio no GitHub.

> üëâ √â aqui onde voc√™ vai definir os fluxos de automa√ß√£o que o GitHub deve executar automaticamente ‚Äî chamados de workflows.

Esses workflows s√£o escritos em `YAML (.yml)`, e dizem ao GitHub:

 - Quando executar algo (gatilhos/triggers como push, pull request, etc.);
 - Em qual ambiente executar (como Ubuntu, Windows, etc.);
 - O que deve ser executado (os comandos, scripts ou jobs).

Por exemplo:

```bash
your-repo/
‚îÇ
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ ci.yml
‚îÇ       ‚îî‚îÄ‚îÄ deploy.yml
```

Cada arquivo `.yml` dentro de [.github/workflows](.github/workflows) representa um workflow independente.

Por exemplo:

 - `ci.yml` ‚Üí Faz testes autom√°ticos e checa o c√≥digo (CI = Continuous Integration);
 - `deploy.yml` ‚Üí Envia o c√≥digo para o servidor (CD = Continuous Deployment).

#### `O que √© um ‚Äúworkflow‚Äù no GitHub Actions?`

Um *workflow* √© composto de:

 - **Trigger (gatilho)** ‚Üí Quando ele deve rodar;
 - **Jobs (tarefas)** ‚Üí O que ele faz (como rodar testes, buildar imagem, etc.);
 - **Steps (passos)** ‚Üí Os comandos de cada tarefa

#### `Cobrindo os testes com codecov.io`

 - **Acesse: https://app.codecov.io/gh**
   - Selecione seu reposit√≥rio.
 - **"Select a setup option"**:
   - Selecione -> Using GitHub Actions
 - **"Step 1: Output a Coverage report file in your CI"**
   - Selecione -> Pytest
   - ...
 - **Step 3: add token as repository secret**
   - Copie -> CODECOV_TOKEN
   - Copie -> SUA-CHAVE-SECRETA
   - **NOTE:** Voc√™ vai utilizar eles no workflow `.github/workflows/ci.yml` (ex: [env](#env)).

√ìtimo, agora voc√™ j√° tem a chave secreta para o Codecov, v√° em:

 - Seu projeto/settings;
 - secrets and variables:
   - Actions.

Continuando, agora voc√™ vai clicar em `New repository secret` e adicionar:

 - Name: `CODECOV_TOKEN`
 - Secret: `YOUR-CODECOV-TOKEN`
 - Finalmente, clicar em "Add Secret".

Por fim, vamos adicionar os badges do **Codecov** e do **Pipeline**:

 - Para obter um *Pipeline badge*, altere o link abaixo para o reposit√≥rio/CI-CD do seu projeto:
   - `[![CI](https://github.com/rodrigols89/ragproject/actions/workflows/ci.yml/badge.svg)](https://github.com/rodrigols89/ragproject/actions/workflows/ci.yml)`
 - Para obter um *Codecov badge*:
   - Acesse [https://app.codecov.io/gh/](https://app.codecov.io/gh/)
   - Selecione o projeto que est√° sendo monitorado pela cobertura de testes.
   - V√° em **Settings > Badges & Graphs > Markdown** e copie o badge gerado:



















































---

<div id="github-workflows-lint-yml"></div>

## `Criando o workflow lint.yml`

> Aqui n√≥s vamos cria o *workflow* que vai fazer a *verifica√ß√£o* de *lint* no c√≥digo.

De in√≠cio, vamos come√ßar dando um nome a esse workflow:

[lint.yml](../.github/workflows/lint.yml)
```yaml
name: Lint
```

Agora, n√≥s vamos adicionar os gatilhos (triggers) que acionar√£o esse workflow:

[lint.yml](../.github/workflows/lint.yml)
```yaml
on:
  push:
    branches: [ ci-cd ]
    paths:
      - "**/*.py"
      - "requirements*.txt"
      - "pyproject.toml"
  pull_request:
    branches: [ ci-cd ]
    paths:
      - "**/*.py"
      - "requirements*.txt"
      - "pyproject.toml"
```

 - `on:`
   - Voc√™ pode pensar no comando `on`, como:
     - "Toda vez que o reposit√≥rio receber o comando *x ("push" e "pull_request" no nosso caso)*.
 - `push:`
     - Gatilho (trigger) do workflow.
   - `branches: [ ci-cd ]`
     - Branches que executar√£o as tarefas, no nosso caso, √© *"ci-cd"*;
     - ci-cd j√° garante a qualidade do c√≥digo;
     - *"main"* normalmente s√≥ recebe merges j√° validados.
   - `paths:`
     - S√≥ executa quando houver mudan√ßas em `arquivos Python`, `requirements*.txt`, `pyproject.toml`.
 - `pull_request:`
   - Outro gatilho gatilho (trigger) do workflow.
   - `branches: [ ci-cd ]`
     - Novamente, s√≥ ser√° acionado na branch *"ci-cd"*
   - `paths:`
     - Novamente, s√≥ √© executado quando houver mudan√ßas em `arquivos Python`, `requirements*.txt`, `pyproject.toml`.

> **NOTE:**  
> Essas configura√ß√µes aqui s√£o referentes aos gatilhos que for√ßam o workflow a rodar.

Continundo, agora n√≥s vamos criar uma se√ß√£o para `jobs`:

[lint.yml](../.github/workflows/lint.yml)
```yaml
jobs:
  ...
```

 - `jobs:`
   - Um workflow pode ter v√°rios **"jobs"** (testar, build, deploy, lint, etc.).
   - Mas, nesse nosso exemplo s√≥ vamos ter o *"lint"*.

Agora n√≥s vamos criar uma tarefa (job) com o nome `lint-ci` que vai ser executada no SO `ubuntu-latest`:

[lint.yml](../.github/workflows/lint.yml)
```yaml
jobs:
  lint-ci:
    runs-on: ubuntu-latest
```

 - `lint-ci`
   - √â o nome da tarefa (job).
 - `runs-on: ubuntu-latest`
   - A *runner (SO)* que vai rodar essa tarefa.

Agora, dentro dessa `tarefa (lint-ci)`, na m√°quina `ubuntu-latest`, n√≥s vamos ter alguns `passos (steps)` que ser√£o executados:

[lint.yml](../.github/workflows/lint.yml)
```yaml
jobs:
  lint-ci:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies for lint
        run: |
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install --upgrade pip
          pip install ruff
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run Ruff (lint)
        run: |
          source .venv/bin/activate
          ruff check .
```

 - `steps`
   - Uma lista de passos que v√£o ser executados na runner.
 - `name: Checkout`
 - `uses: actions/checkout@v4`
   - Diz ao GitHub que queremos usar a Action oficial para clonar o reposit√≥rio.
 - `name: Set up Python`
 - `uses: actions/setup-python@v4`
   - `with:`
     - `python-version: "3.12"`
     - Action oficial de instala√ß√£o do Python (com a vers√£o 3.12).

> **NOTE:**  
> N√£o vou explicar os demais `steps` linh a linha porque a partir deste ponto acredito que seja possivel entender a maioria dos comandos.

> **O comando `name:` pode ser qualquer texto.**  
> Ele serve apenas como identificador visual no *GitHub Actions*, para voc√™ conseguir ler no painel.

### `Workflow completo`

[lint.yml](../.github/workflows/lint.yml)
```yaml
name: Lint

on:
  push:
    branches: [ ci-cd ]
    paths:
      - "**/*.py"
      - "requirements*.txt"
      - "pyproject.toml"
  pull_request:
    branches: [ ci-cd ]
    paths:
      - "**/*.py"
      - "requirements*.txt"
      - "pyproject.toml"

jobs:
  lint-ci:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies for lint
        run: |
          python -m venv .venv
          source .venv/bin/activate
          python -m pip install --upgrade pip
          pip install ruff
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Run Ruff (lint)
        run: |
          source .venv/bin/activate
          ruff check .
```

> **NOTE:**  
> Continuando, agora √© s√≥ fazer o commit e push ou pull_request na branche ci-cd que o workflow ser√° acionado.









































































































<!--- ( Testes ) --->

---

<div id="manage-py-tests"></div>

## `Criando testes para o manage.py`

> Aqui n√≥s vamos criar alguns testes simples (s√≥ para o nosso Pytest passar no pre-commit) para o [manage.py](../manage.py).

### `test_main_sets_django_settings_module_when_not_set()`

De in√≠cio, vamos criar um arquivo chamado [test_manage.py](../tests/test_manage.py) e importar a fun√ß√£o `main()` do arquivo [manage.py](../manage.py):

[test_manage.py](../tests/test_manage.py)
```python
"""Tests for manage.py."""
import manage

main = manage.main
```

Agora vamos implementar uma fun√ß√£o de teste chamada `test_main_sets_django_settings_module_when_not_set` que vai ser respons√°vel por:

 - Verificar se a fun√ß√£o `main()` do [manage.py](../manage.py) configura corretamente a vari√°vel de ambiente `DJANGO_SETTINGS_MODULE` quando ela ainda n√£o existe;
 - E se o Django √© executado com os argumentos certos.

> **Em outras palavras:**  
> üëâ Queremos ter certeza de que o manage.py funciona mesmo quando o ambiente ainda n√£o est√° configurado.

Vamos come√ßar criando uma fun√ß√£o que come√ßa com `test_` e que recebe `monkeypatch` como argumento:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):
    ...
```

 - **O nome da fun√ß√£o come√ßa com `test_` ‚Üí pytest reconhece automaticamente**
 - **monkeypatch √© uma ferramenta do pytest que permite:**
   - alterar vari√°veis de ambiente
   - substituir fun√ß√µes
   - simular comportamentos
   - **NOTE:** üí° Pense no `monkeypatch` como um *"controle remoto do ambiente durante o teste"*.

Agora, vamos criar um **‚Äúregistrador de chamadas‚Äù**:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    called_args = []
```

 - Criamos uma lista vazia para guardar informa√ß√µes depois.
 - üëâ Vamos us√°-la para verificar:
   - se uma fun√ß√£o foi chamada
   - com quais argumentos ela foi chamada

Continuando, agora n√≥s vamos criar uma **fun√ß√£o falsa (mock)**: 

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    def mock_execute(args):
        called_args.append(args)
```

 - **Aqui estamos criando uma fun√ß√£o falsa que vai substituir:**
   - `execute_from_command_line`
 - **Em vez de:**
   - iniciar o Django
   - rodar comandos reais
 - **Ela apenas:**
   - recebe os argumentos
   - guarda esses argumentos em called_args (com .append())

> **NOTE:**  
> ‚úÖ Isso deixa o teste r√°pido e seguro.

Continuando, no arquivo [manage.py](../manage.py) dentro da fun√ß√£o `main()`, n√≥s temos a vari√°vel de ambiente `DJANGO_SETTINGS_MODULE`:

[manage.py](../manage.py)
```python
def main():
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')

    ...
```

Agora, n√≥s vamos garantir que essa vari√°vel de ambiente (`DJANGO_SETTINGS_MODULE`) n√£o exista no nosso teste:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    monkeypatch.delenv('DJANGO_SETTINGS_MODULE', raising=False)
```

Continuando, agora n√≥s vamos substituir a `fun√ß√£o real (execute_from_command_line)` pela `fun√ß√£o falsa (mock_execute)`:

[test_manage.py](../tests/test_manage.py)
```python
import manage

def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    monkeypatch.setattr(manage, 'execute_from_command_line', mock_execute)
```

Aqui acontece a m√°gica:

 - **Onde o c√≥digo original (import manage) chamaria:**
   - `execute_from_command_line`
 - **Agora ele chamar√°:**
   - `mock_execute(...)`

> **NOTE:**  
> üëâ Assim conseguimos observar o comportamento sem efeitos colaterais.

Agora, n√≥s vamos simular um comando digitado no terminal:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    monkeypatch.setattr(sys, 'argv', ['manage.py', 'help'])
```

 - **Isso simula o comando:**
   - `python manage.py help`
 - Ou seja:
   - `sys.argv[0]` ‚Üí manage.py
   - `sys.argv[1]` ‚Üí help

> **NOTE:**  
> üí° √â como se o usu√°rio tivesse rodado o comando no terminal.

Agora, n√≥s vamos executar a fun√ß√£o testada:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    main()
```

Neste momento a fun√ß√£o `main()`:

 - percebe que `DJANGO_SETTINGS_MODULE` n√£o existe
 - define essa vari√°vel
 - chama `execute_from_command_line`
 - que agora est√° mockada

Lembram, que no arquivo [manage.py](../manage.py) n√≥s criamos a vari√°vel de ambiente `DJANGO_SETTINGS_MODULE` que recebeu o valor `core.settings`?

[manage.py](../manage.py)
```python
def main():
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')
```

Ent√£o, agora n√≥s vamos criar um `assert` que vai ser verificar se a vari√°vel de ambiente `DJANGO_SETTINGS_MODULE` √© igual a `core.settings`:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    assert os.environ.get('DJANGO_SETTINGS_MODULE') == 'core.settings'
```

Se voc√™ rodar esse teste agora, obrigatoriamente ele deve passar:

**OUTPUT:**
```bash
tests/test_manage.py::test_main_sets_django_settings_module_when_not_set PASSED
```

Mas ainda falta um `assert` que verificar se o Django foi chamado corretamente:

[test_manage.py](../tests/test_manage.py)
```python
def test_main_sets_django_settings_module_when_not_set(monkeypatch):

    ...

    assert called_args == [['manage.py', 'help']]
```

Aqui confirmamos que:

 - `execute_from_command_line` foi chamado
 - recebeu exatamente os argumentos simulados

**OUTPUT:**
```bash
tests/test_manage.py::test_main_sets_django_settings_module_when_not_set PASSED
```

> **NOTE:**  
> Essa minha fun√ß√£o tem 2 `asserts` o que **n√£o √© ideal** o interessante √© ter um teste por vez.





















































---

<div id="test-admin-url-is-registered"></div>

## `Testando se a URL /admin/ est√° registrada corretamente`

> Aqui, n√≥s vamos criar um teste automatizado simples para garantir que a URL `/admin/` est√° corretamente registrada no sistema de rotas do Django.

Vamos come√ßar criando uma **fun√ß√£o de teste** chamada `test_admin_url_is_registered()`:

[tests/test_urls.py](../tests/test_urls.py)
```python
def test_admin_url_is_registered():
    """
    Testa se a URL /admin/ est√° registrada no sistema de rotas do Django.
    """
    ...
```

### `üÖ∞Ô∏è Arrange ‚Äî Preparando o cen√°rio`

Continuando, nesta etapa (Arrange), n√≥s n√£o vamos precisar preparar quase nada, porque:

 - o Django j√° carrega automaticamente o `ROOT_URLCONF`
 - o arquivo `core/urls.py` j√° est√° configurado no projeto

Mesmo assim, precisamos importar a fun√ß√£o que ser√° usada para testar URLs:

[tests/test_urls.py](../tests/test_urls.py)
```python
from django.urls import resolve
```

 - A fun√ß√£o `resolve()`:
   - recebe uma URL como string
   - tenta encontrar essa URL no `urlpatterns = [...]`
   - retorna informa√ß√µes sobre a rota encontrada

### `üÖ∞Ô∏èüÖ∞Ô∏è Act ‚Äî Executando a a√ß√£o`

Agora vamos executar a a√ß√£o (Act) principal do teste que vai ser **pedir para o Django resolver a URL `/admin/`**:

[tests/test_urls.py](../tests/test_urls.py)
```python
from django.urls import resolve


def test_admin_url_is_registered():
    """
    Testa se a URL /admin/ est√° registrada no sistema de rotas do Django.
    """

    # Arrange
    # (n√£o √© necess√°rio preparar nada al√©m do carregamento do Django)

    # Act
    match = resolve('/admin/')
```

 - **O que a fun√ß√£o `resolve()` faz?**
   - Ela serve para descobrir qual view o Django executaria ao receber uma determinada URL.
   - Em outras palavras:
     - üëâ ‚ÄúSe um usu√°rio acessasse essa URL no navegador, qual c√≥digo (view) seria chamado?‚Äù
 - **Quais par√¢metros `resolve()` recebe?**
   - 1Ô∏è‚É£ `path (obrigat√≥rio)`
     - √â o caminho da URL, exatamente como o Django receberia na requisi√ß√£o HTTP
     - Por exemplo, `/admin/`
   - 2Ô∏è‚É£ `urlconf (opcional)`
     - Permite especificar manualmente um conjunto de URLs
     - Normalmente n√£o √© usado em testes comuns
 - **O que a fun√ß√£o resolve() retorna?**
   - Se a URL for encontrada, resolve() retorna um objeto do tipo:
     - `django.urls.resolvers.ResolverMatch`
   - Principais atributos retornados:
     - `match.func` ‚Üí A view que ser√° chamada
     - `match.view_name` ‚Üí Nome da view (se houver)
     - `match.args` ‚Üí Argumentos posicionais da URL
     - `match.kwargs` ‚Üí Argumentos nomeados da URL
     - `match.route` ‚Üí Padr√£o da rota que deu match

### `üÖ∞Ô∏èüÖ∞Ô∏èüÖ∞Ô∏è Assert ‚Äî Verificando o resultado`

Continuando, agora vamos criar um √∫nico `assert` que verifique se a URL `/admin/` foi encontrada:

[tests/test_urls.py](../tests/test_urls.py)
```python
from django.urls import resolve


def test_admin_url_is_registered():
    """
    Testa se a URL /admin/ est√° registrada no sistema de rotas do Django.
    """

    # Arrange
    # (n√£o √© necess√°rio preparar nada al√©m do carregamento do Django)

    # Act
    match = resolve('/admin/')

    # Assert
    assert match is not None
```

 - **O que esse assert garante?**
   - Que o Django conseguiu resolver a URL /admin/
   - Que essa rota est√° registrada
   - Que o arquivo core/urls.py est√° funcionando corretamente
   - üëâ Se a URL for removida, alterada ou quebrada, esse teste falha.

### `üìÑ C√≥digo final completo do teste`

[tests/test_urls.py](../tests/test_urls.py)
```python
from django.urls import resolve


def test_admin_url_is_registered():
    """
    Testa se a URL /admin/ est√° registrada no sistema de rotas do Django.
    """

    # Arrange
    # (n√£o √© necess√°rio preparar nada al√©m do carregamento do Django)

    # Act
    match = resolve('/admin/')

    # Assert
    assert match is not None
```

### `Testando`

Se voc√™ desejar rodar esse teste espec√≠fico voc√™ pode executar o seguinte comando:

```bash
pytest -s -x --cov=. -vv tests/test_urls.py::test_admin_url_is_registered
```





















































---

<div id="test-asgi-application-is-created"></div>

## `Testando se a aplica√ß√£o ASGI do Django √© criada corretamente`

Aqui, n√≥s vamos criar um teste automatizado simples para garantir que o arquivo `core/asgi.py` est√° configurado corretamente e que o Django consegue criar a aplica√ß√£o ASGI do projeto.

> **üëâ Em termos simples:**  
> ‚ÄúEsse teste garante que o Django conseguiu inicializar a aplica√ß√£o ASGI sem erros.‚Äù

Esse teste √© importante porque:

 - o ASGI √© usado por servidores como Daphne, Uvicorn e Hypercorn
 - qualquer erro nesse arquivo impede o projeto de subir em produ√ß√£o

Vamos come√ßar criando uma **fun√ß√£o de teste** chamada `test_asgi_application_is_created()`:

[tests/test_asgi.py](../tests/test_asgi.py)
```python
def test_asgi_application_is_created():
    """
    Testa se a aplica√ß√£o ASGI do Django √© criada corretamente.
    """
```

### `üÖ∞Ô∏è Arrange ‚Äî Preparando o cen√°rio`

Nesta etapa, n√≥s n√£o precisamos preparar quase nada manualmente.

Isso porque:

 - o Django j√° carrega automaticamente as configura√ß√µes
 - o arquivo `core/asgi.py` j√° define:

```python
os.environ.setdefault(
    'DJANGO_SETTINGS_MODULE',
    'core.settings',
)
```

O que precisamos fazer aqui √© importar o objeto que ser√° testado.

[tests/test_asgi.py](../tests/test_asgi.py)
```python
from core.asgi import application


def test_asgi_application_is_created():
    """
    Testa se a aplica√ß√£o ASGI do Django √© criada corretamente.
    """
```

> **üîç O que acontece nesse import?**

 - O Python executa o arquivo core/asgi.py
 - O Django:
   - garante que `DJANGO_SETTINGS_MODULE` est√° definido
 - chama `get_asgi_application()` (que est√° em `core/asgi.py`)
 - O objeto `application` √© criado

### `üÖ∞Ô∏èüÖ∞Ô∏è Act ‚Äî Executando a a√ß√£o`

Aqui a a√ß√£o √© m√≠nima, mas ainda existe:

> üëâ N√≥s simplesmente acessamos o objeto application.

[tests/test_asgi.py](../tests/test_asgi.py)
```python
from core.asgi import application


def test_asgi_application_is_created():
    """
    Testa se a aplica√ß√£o ASGI do Django √© criada corretamente.
    """

    # Arrange
    # (nenhuma prepara√ß√£o manual √© necess√°ria)

    # Act
    app = application
```

Isso confirma que:

 - o import foi bem-sucedido
 - o objeto existe em mem√≥ria

### `üÖ∞Ô∏èüÖ∞Ô∏èüÖ∞Ô∏è Assert ‚Äî Verificando o resultado`

Agora vamos criar um √∫nico `assert`, focando em uma coisa s√≥:

[tests/test_asgi.py](../tests/test_asgi.py)
```python
from core.asgi import application


def test_asgi_application_is_created():
    """
    Testa se a aplica√ß√£o ASGI do Django √© criada corretamente.
    """

    # Arrange
    # (nenhuma prepara√ß√£o manual √© necess√°ria)

    # Act
    app = application

    # Assert
    assert callable(app)
```

> **O que esse assert garante?**

 - **Que application:**
   - existe
   - √© um objeto cham√°vel
 - **Ou seja:**
   - o Django criou corretamente a aplica√ß√£o ASGI
 - **Se houver erro em:**
   - settings
   - imports
   - middleware
   - apps instalados
   - **NOTE:** esse teste falha automaticamente.

### `üìÑ C√≥digo final completo do teste`

[tests/test_asgi.py](../tests/test_asgi.py)
```python
from core.asgi import application


def test_asgi_application_is_created():
    """
    Testa se a aplica√ß√£o ASGI do Django √© criada corretamente.
    """

    # Arrange
    # (nenhuma prepara√ß√£o manual √© necess√°ria)

    # Act
    app = application

    # Assert
    assert callable(app)
```


### `Testando`

Se voc√™ desejar rodar esse teste espec√≠fico voc√™ pode executar o seguinte comando:

```bash
pytest -s -x --cov=. -vv tests/test_asgi.py::test_asgi_application_is_created
```

---

**Rodrigo** **L**eite da **S**ilva - **rodrigols89**
